{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JuMP.jl: Beyond the Basics\n",
    "In the first part of our `JuMP.jl` introduction, we learned how to model/solve simple optimization problems with scalar decision variables. In this part, we take a deeper dive into `JuMP.jl`'s features and to have the tools we need to tackle real problems.\n",
    "\n",
    "## Resources\n",
    "Again, for reference, here are resources to learn more and get help:\n",
    "- The tutorials, examples, manuals, and guides in `JuMP.jl`'s documentation: https://jump.dev/JuMP.jl/stable/\n",
    "- The Julia optimization forum: https://discourse.julialang.org/c/domain/opt/13\n",
    "- Julia Programming for Operations Research 2/e (not always up-to-date): https://www.softcover.io/read/7b8eb7d0/juliabook2/introduction\n",
    "\n",
    "## Models and Solvers\n",
    "We have learned how to create `Model` objects with an optimizer using its default settings. Now let's take a closer look.\n",
    "\n",
    "### Solver Specification\n",
    "As before, we can create by passing an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, HiGHS\n",
    "\n",
    "model = Model(HiGHS.Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can create the `Model` add the optimizer later (any time before calling `optimize!`) via `set_optimizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "set_optimizer(model, HiGHS.Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all allows us to create a `Model` object and attach a solver to it. However, where possible the optimizer should be provided directly to the `Model` object for better error messaging (e.g., adding a constraint that the solver doesn't support). \n",
    "\n",
    "Often times we may wish to specify options (attributes) to the solver. One way to accomplish this is via `optimizer_with_attributes`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(optimizer_with_attributes(HiGHS.Optimizer, \"output_flag\" => false, \"presolve\" => \"on\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the attributes are solver specific and can be found by checking the documentation associated with each solver. We can also specify/modify attributes using `set_optimizer_attribute`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "set_optimizer_attribute(model, \"output_flag\", false)\n",
    "set_optimizer_attribute(model, \"presolve\", \"on\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, `JuMP.jl` provides a few solver-agnostic methods for setting common attributes such as turning the output off and setting a time limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "set_silent(model) # turn the output printing off\n",
    "set_time_limit_sec(model, 60.0) # set a time limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Writing/Reading\n",
    "`JuMP.jl` does support writing models to files via `write_to_file` and creating a model from a file via `read_from_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(model, \"model.mps\")\n",
    "read_model = read_from_file(\"model.mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on supported files and details about this refer to https://jump.dev/JuMP.jl/stable/manual/models/#Write-a-model-to-file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MathOptInterface.jl` Backends and Performance\n",
    "More advanced users may wish to better understand what is going on behind the scenes and squeeze out some better performance. This section will touch upon some of these considerations at a surface level. A more throughout discussion is provided at https://jump.dev/JuMP.jl/stable/manual/models/#Backends\n",
    "\n",
    "`JuMP.jl` `Model`s are thin wrappers `MathOptInterface.jl` models which are what actually store the optimization problem and interface to the solvers. These model(s) employed by `MathOptInterface.jl` behind the scenes are called the backend and can be accessed via `backend`. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "b = backend(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is quite a bit going on here in addition to the `MOI` `HiGHS.Optimizer` model. We'll briefly describe these different layers. \n",
    "\n",
    "The `MOIU.CachingOptimizer` is a layer that allows us to build models incrementally (e.g., adding variables one by one) even if the solver doesn't support that. All the information is stored in `MOIU.UniversalFallback{MOIU.Model{Float64}}` which acts as a cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.model_cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cache model can always be build/modified incrementally. This is then used to efficiently update the optimizer model `MOIB.LazyBridgeOptimizer{HiGHS.Optimizer}` when appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the optimizer model (`HiGHS.Optimizer`) is wrapped in `MOIB.LazyBridgeOptimizer`. The bridge layer allows constraints to be transformed (i.e., bridged) to forms that a solver supports. For example, we might need to split an interval constraint into 2 inequality constraints.\n",
    "\n",
    "If constraint bridges are unnecessary for our model, and we wish to decrease the start-up latency, we can use `add_bridges = false` when we create the `JuMP.jl` `Model` to eliminate this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer; add_bridges = false)\n",
    "backend(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `MOIB.LazyBridgeOptimizer` layer on the optimizer is now gone. \n",
    "\n",
    "To take this a step further, we can eliminate the cache model entirely by creating a model via `direct_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = direct_model(HiGHS.Optimizer())\n",
    "backend(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only have the `HiGHS.Optimizer` as the backend model. This avoids the overhead of the caching model which effectively creates two copies of our model. However, there are a few caveats:\n",
    "- This will not work for solvers that cannot be build incrementally (e.g., Ipopt)\n",
    "- There are no bridges to reformulate constraints into acceptable forms\n",
    "- The behavior of querying the solution after modification to the problem is solver specific\n",
    "\n",
    "So direct models can help increase performance, but should be used carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "Let's take a deeper dive into more of the things we can do with `@variable`.\n",
    "\n",
    "### Containers and Sets\n",
    "We have already seen how to add individual scalar variables, now let's see how to add multiple variables at once.\n",
    "\n",
    "`JuMP.jl` uses 3 data structures to store variable collections:\n",
    "- `Array`s: The native Julia arrays\n",
    "- `DenseAxisArray`s: Dense arrays with arbitrary indices\n",
    "- `SparseAxisArray`s: Sparse arrays with arbitrary indices\n",
    "\n",
    "Arrays are created using integer indices of the form `1:n`. For instance, the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, a[1:2, 1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a 2 x 4 matrix of variables that is stored to `a` which we can index and use in defining our problem.\n",
    "\n",
    "We can also create an n-dimensional vector variable $x \\in \\mathbb{R}^n$ with upper and lower bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "l = [1, 2, 3, 4, 5]\n",
    "u = [10, 11, 12, 13, 14]\n",
    "\n",
    "@variable(model, l[i] <= x[i = 1:n] <= u[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we declare an index `i` to help us define the appropriate values. \n",
    "\n",
    "We can use other index forms that don't conform to `1:n` and make `DenseAxisArray`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, z[i = 2:3, j = 1:2:3] >= i + 2j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't even have to use integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, w[[\"red\", \"blue\"], 1:5] <= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For indices that do not form a rectangular set, a `SparseAxisArray` is formed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, u[i = 1:2, j = i:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even add a conditional statement after a `;` when defining indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, v[i = 1:3, j = 1:4; i + j <= 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrality\n",
    "To specify integer variables, we need only add the `Int` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, integer_x, Int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by setting `integer = true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, integer_z, integer = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we create binary variables via the `Bin` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, binary_x, Bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by using `binary = true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, binary_z, binary = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Nodal Variables\n",
    "**Problem**\n",
    "- Create a variable named `xp`\n",
    "- `xp` should be integer valued between 0 and 3\n",
    "- `xp` should be indexed over each arc `(i, j)` in `arcs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcs = [(1, 2), (1, 3), (3, 2), (2, 4)]\n",
    "\n",
    "# PUT CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Options\n",
    "There are a variety of other things we can do with variables. We can create a fixed variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, x_fixed == 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the initial guess to pass on to the solver via `start`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, q, start = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify lower/upper bounds via the keyword arguments `lower_bound` and `upper_bound`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymous Variables\n",
    "Normally when we create variables they are registered in the model, so we can access them via `model[:var_name]`. For instance, consider a typical definition of a scalar variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, x >= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does a few things:\n",
    "- Add a scalar variable with a name `\"x\"` to `model`\n",
    "- Add a lower bound of 0\n",
    "- Create a Julia variable `x` that stores a reference to the optimization variable\n",
    "- Registers that Julia variable in `model` such that is can be accessed via `model[:x]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show x \n",
    "@show model[:x];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this registration means we cannot add another variable with the same name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, x == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this behavior is prohibitive, we can define an anonymous variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = @variable(model, lower_bound = 0, base_name = \"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds an optimization variable to the model with a lower bound and name `\"x\"`, but doesn't register it. We store the resulting variable reference in the Julia variable `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Variables\n",
    "There are a variety of ways to change variables after they are created. Some common methods include:\n",
    "- `set_lower_bound`\n",
    "- `set_upper_bound`\n",
    "- `fix`\n",
    "- `set_start_value`\n",
    "- `set_binary`\n",
    "- `set_integer`\n",
    "- `delete`\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_upper_bound(x, 10)\n",
    "set_integer(x)\n",
    "delete(model, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more things we can do, see https://jump.dev/JuMP.jl/stable/manual/variables/ to learn more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions\n",
    "Sometimes we may want to use a mathematical expression in multiple constraints and/or the objective. We can create expressions using `@expression`. To motivate this, let's create a model with variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, x[1:2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine/Quadratic Expressions\n",
    "We can create affine/quadratic expressions using `@expression`. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_expr = @expression(model, x[1]^2 - 3x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates an anonymous expression that we can use elsewhere. We can also create named/registered expressions by adding a name argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@expression(model, my_expr, x[1]^2 - 3x[2])\n",
    "@show my_expr;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a Julia variable `my_expr` to access the expression and registers it, so we can get it by indexing `model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[:my_expr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a container of expressions, just like we can for variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@expression(model, expr[i = 1:2], 4x[i]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra\n",
    "For linear/quadratic expressions, `JuMP.jl` supports linear algebra operations. For instance, consider $x^T A y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, y[1:3])\n",
    "A = [1 2 4; 2 6 1]\n",
    "\n",
    "@expression(model, x' * A * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@expression(model, sum(x[i] * A[i, j] * y[j] for j in 1:3, i in 1:2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Expressions\n",
    "Any expressions that aren't linear/quadratic must be created using `@NLexpression`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@NLexpression(model, nlexpr[i = 1:2], 2sin(x[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library of built-in univariate functions is derived those listed in https://github.com/JuliaMath/Calculus.jl/blob/master/src/differentiate.jl. \n",
    "\n",
    "If we want to use some other nonlinear function that is not natively supported, we can add our own! For instance, let's add the `logerfcx` from `SpecialFunctions.jl` using the `register` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SpecialFunctions\n",
    "\n",
    "register(model, :logerfcx, 1, logerfcx, autodiff = true) # register a univariate function `logerfcx` and use auto differientiation for gradients\n",
    "@NLexpression(model, [i = 1:2], logerfcx(x[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on nonlinear expressions see https://jump.dev/JuMP.jl/stable/manual/nlp/#Nonlinear-Modeling.\n",
    "\n",
    "For performance reasons, `@expression` should be used when possible. This will make evaluating the hessian easier later on. Also, note that nonlinear expressions do not support linear algebra currently.\n",
    "\n",
    "Development is currently underway to overhaul the entire nonlinear interface and remove the need for `@NLexpression` and its limitations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "We have already seen how to set linear/quadratic objectives using `@objective`. Let's learn a little more.\n",
    "\n",
    "### Modification\n",
    "Once an objective is set, we can modify by simply calling `@objective` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to play with\n",
    "model = Model()\n",
    "@variable(model, x[1:2])\n",
    "\n",
    "# Set objective\n",
    "@objective(model, Min, 2x[1] + 3x[2])\n",
    "@show objective_function(model)\n",
    "\n",
    "# Change the objective\n",
    "@objective(model, Min, 4x[1] + 3x[2])\n",
    "@show objective_function(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all we want to do is change a linear coefficient, then we can use `set_objective_coefficient` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_objective_coefficient(model, x[1], 2)\n",
    "objective_function(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Objectives\n",
    "In analogous manner to expressions, non-quadratic/affine objectives must be specified via `@NLobjective`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@NLobjective(model, Min, log(x[1]) + x[2]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These incur the same limitations as `@NLexpression` and will be reworked with the current overhaul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Linear Algebra Objective\n",
    "**Problem**\n",
    "- Create a quadratic objective\n",
    "- The function is $x^T A y + b^T y + c^Tx$\n",
    "- Maximize the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1 3 6; -9 2 1]\n",
    "b = [3, -2, 0]\n",
    "c = [2, 1]\n",
    "\n",
    "# PUT CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "Previously, we saw how to add simple scalar constraints. We will now take a deeper dive into using constraints in `JuMP.jl`.\n",
    "\n",
    "Let's setup a model and variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, x[1:2])\n",
    "@variable(model, y[1:3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Sets/Containers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
