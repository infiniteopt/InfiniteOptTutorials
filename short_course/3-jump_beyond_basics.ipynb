{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `JuMP.jl`: Beyond the Basics\n",
    "In the first part of our `JuMP.jl` introduction, we learned how to model/solve simple optimization problems with scalar decision variables. In this part, we take a deeper dive into `JuMP.jl`'s features and to have the tools we need to tackle real problems.\n",
    "\n",
    "## Resources\n",
    "Again, for reference, here are resources to learn more and get help:\n",
    "- The tutorials, examples, manuals, and guides in `JuMP.jl`'s documentation: https://jump.dev/JuMP.jl/stable/\n",
    "- The Julia optimization forum: https://discourse.julialang.org/c/domain/opt/13\n",
    "- Julia Programming for Operations Research 2/e (not always up-to-date): https://www.softcover.io/read/7b8eb7d0/juliabook2/introduction\n",
    "\n",
    "## Models and Solvers\n",
    "We have learned how to create `Model` objects with an optimizer using its default settings. Now let's take a closer look.\n",
    "\n",
    "### Solver Specification\n",
    "As before, we can create by passing an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, HiGHS\n",
    "\n",
    "model = Model(HiGHS.Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can create the `Model` add the optimizer later (any time before calling `optimize!`) via `set_optimizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "set_optimizer(model, HiGHS.Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all allows us to create a `Model` object and attach a solver to it. However, where possible the optimizer should be provided directly to the `Model` object for better error messaging (e.g., adding a constraint that the solver doesn't support). \n",
    "\n",
    "Often times we may wish to specify options (attributes) to the solver. One way to accomplish this is via `optimizer_with_attributes`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(optimizer_with_attributes(HiGHS.Optimizer, \"output_flag\" => false, \"presolve\" => \"on\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the attributes are solver specific and can be found by checking the documentation associated with each solver. We can also specify/modify attributes using `set_optimizer_attribute`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "set_optimizer_attribute(model, \"output_flag\", false)\n",
    "set_optimizer_attribute(model, \"presolve\", \"on\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, `JuMP.jl` provides a few solver-agnostic methods for setting common attributes such as turning the output off and setting a time limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "set_silent(model) # turn the output printing off\n",
    "set_time_limit_sec(model, 60.0) # set a time limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Writing/Reading\n",
    "`JuMP.jl` does support writing models to files via `write_to_file` and creating a model from a file via `read_from_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(model, \"model.mps\")\n",
    "read_model = read_from_file(\"model.mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on supported files and details about this refer to https://jump.dev/JuMP.jl/stable/manual/models/#Write-a-model-to-file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MathOptInterface.jl` Backends and Performance\n",
    "More advanced users may wish to better understand what is going on behind the scenes and squeeze out some better performance. This section will touch upon some of these considerations at a surface level. A more throughout discussion is provided at https://jump.dev/JuMP.jl/stable/manual/models/#Backends\n",
    "\n",
    "`JuMP.jl` `Model`s are thin wrappers `MathOptInterface.jl` models which are what actually store the optimization problem and interface to the solvers. These model(s) employed by `MathOptInterface.jl` behind the scenes are called the backend and can be accessed via `backend`. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "b = backend(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is quite a bit going on here in addition to the `MOI` `HiGHS.Optimizer` model. We'll briefly describe these different layers. \n",
    "\n",
    "The `MOIU.CachingOptimizer` is a layer that allows us to build models incrementally (e.g., adding variables one by one) even if the solver doesn't support that. All the information is stored in `MOIU.UniversalFallback{MOIU.Model{Float64}}` which acts as a cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.model_cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cache model can always be build/modified incrementally. This is then used to efficiently update the optimizer model `MOIB.LazyBridgeOptimizer{HiGHS.Optimizer}` when appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the optimizer model (`HiGHS.Optimizer`) is wrapped in `MOIB.LazyBridgeOptimizer`. The bridge layer allows constraints to be transformed (i.e., bridged) to forms that a solver supports. For example, we might need to split an interval constraint into 2 inequality constraints.\n",
    "\n",
    "If constraint bridges are unnecessary for our model, and we wish to decrease the start-up latency, we can use `add_bridges = false` when we create the `JuMP.jl` `Model` to eliminate this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer; add_bridges = false)\n",
    "backend(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `MOIB.LazyBridgeOptimizer` layer on the optimizer is now gone. \n",
    "\n",
    "To take this a step further, we can eliminate the cache model entirely by creating a model via `direct_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = direct_model(HiGHS.Optimizer())\n",
    "backend(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only have the `HiGHS.Optimizer` as the backend model. This avoids the overhead of the caching model which effectively creates two copies of our model. However, there are a few caveats:\n",
    "- This will not work for solvers that cannot be build incrementally (e.g., Ipopt)\n",
    "- There are no bridges to reformulate constraints into acceptable forms\n",
    "- The behavior of querying the solution after modification to the problem is solver specific\n",
    "\n",
    "So direct models can help increase performance, but should be used carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "Let's take a deeper dive into more of the things we can do with `@variable`.\n",
    "\n",
    "### Containers and Sets\n",
    "We have already seen how to add individual scalar variables, now let's see how to add multiple variables at once.\n",
    "\n",
    "`JuMP.jl` uses 3 data structures to store variable collections:\n",
    "- `Array`s: The native Julia arrays\n",
    "- `DenseAxisArray`s: Dense arrays with arbitrary indices\n",
    "- `SparseAxisArray`s: Sparse arrays with arbitrary indices\n",
    "\n",
    "Arrays are created using integer indices of the form `1:n`. For instance, the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, a[1:2, 1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a 2 x 4 matrix of variables that is stored to `a` which we can index and use in defining our problem.\n",
    "\n",
    "We can also create an n-dimensional vector variable $x \\in \\mathbb{R}^n$ with upper and lower bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "l = [1, 2, 3, 4, 5]\n",
    "u = [10, 11, 12, 13, 14]\n",
    "\n",
    "@variable(model, l[i] <= x[i = 1:n] <= u[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we declare an index `i` to help us define the appropriate values. \n",
    "\n",
    "We can use other index forms that don't conform to `1:n` and make `DenseAxisArray`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, z[i = 2:3, j = 1:2:3] >= i + 2j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't even have to use integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, w[[\"red\", \"blue\"], 1:5] <= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For indices that do not form a rectangular set, a `SparseAxisArray` is formed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, u[i = 1:2, j = i:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even add a conditional statement after a `;` when defining indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, v[i = 1:3, j = 1:4; i + j <= 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrality\n",
    "To specify integer variables, we need only add the `Int` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, integer_x, Int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by setting `integer = true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, integer_z, integer = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we create binary variables via the `Bin` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, binary_x, Bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by using `binary = true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, binary_z, binary = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Nodal Variables\n",
    "**Problem**\n",
    "- Create a variable named `xp`\n",
    "- `xp` should be integer valued between 0 and 3\n",
    "- `xp` should be indexed over each arc `(i, j)` in `arcs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcs = [(1, 2), (1, 3), (3, 2), (2, 4)]\n",
    "\n",
    "# PUT CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Options\n",
    "There are a variety of other things we can do with variables. We can create a fixed variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, x_fixed == 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the initial guess to pass on to the solver via `start`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, q, start = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify lower/upper bounds via the keyword arguments `lower_bound` and `upper_bound`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymous Variables\n",
    "Normally when we create variables they are registered in the model, so we can access them via `model[:var_name]`. For instance, consider a typical definition of a scalar variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, x >= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does a few things:\n",
    "- Add a scalar variable with a name `\"x\"` to `model`\n",
    "- Add a lower bound of 0\n",
    "- Create a Julia variable `x` that stores a reference to the optimization variable\n",
    "- Registers that Julia variable in `model` such that is can be accessed via `model[:x]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show x \n",
    "@show model[:x];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this registration means we cannot add another variable with the same name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, x == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this behavior is prohibitive, we can define an anonymous variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = @variable(model, lower_bound = 0, base_name = \"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds an optimization variable to the model with a lower bound and name `\"x\"`, but doesn't register it. We store the resulting variable reference in the Julia variable `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Variables\n",
    "There are a variety of ways to change variables after they are created. Some common methods include:\n",
    "- `set_lower_bound`\n",
    "- `set_upper_bound`\n",
    "- `fix`\n",
    "- `set_start_value`\n",
    "- `set_binary`\n",
    "- `set_integer`\n",
    "- `delete`\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_upper_bound(x, 10)\n",
    "set_integer(x)\n",
    "delete(model, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more things we can do, see https://jump.dev/JuMP.jl/stable/manual/variables/ to learn more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions\n",
    "Sometimes we may want to use a mathematical expression in multiple constraints and/or the objective. We can create expressions using `@expression`. To motivate this, let's create a model with variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, x[1:2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine/Quadratic Expressions\n",
    "We can create affine/quadratic expressions using `@expression`. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_expr = @expression(model, x[1]^2 - 3x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates an anonymous expression that we can use elsewhere. We can also create named/registered expressions by adding a name argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@expression(model, my_expr, x[1]^2 - 3x[2])\n",
    "@show my_expr;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a Julia variable `my_expr` to access the expression and registers it, so we can get it by indexing `model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[:my_expr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a container of expressions, just like we can for variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@expression(model, expr[i = 1:2], 4x[i]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra\n",
    "For linear/quadratic expressions, `JuMP.jl` supports linear algebra operations. For instance, consider $x^T A y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, y[1:3])\n",
    "A = [1 2 4; 2 6 1]\n",
    "\n",
    "@expression(model, x' * A * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@expression(model, sum(x[i] * A[i, j] * y[j] for j in 1:3, i in 1:2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Expressions\n",
    "Any expressions that aren't linear/quadratic must be created using `@NLexpression`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@NLexpression(model, nlexpr[i = 1:2], 2sin(x[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library of built-in univariate functions is derived those listed in https://github.com/JuliaMath/Calculus.jl/blob/master/src/differentiate.jl. \n",
    "\n",
    "If we want to use some other nonlinear function that is not natively supported, we can add our own! For instance, let's add the `logerfcx` from `SpecialFunctions.jl` using the `register` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SpecialFunctions\n",
    "\n",
    "register(model, :logerfcx, 1, logerfcx, autodiff = true) # register a univariate function `logerfcx` and use auto differientiation for gradients\n",
    "@NLexpression(model, [i = 1:2], logerfcx(x[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on nonlinear expressions see https://jump.dev/JuMP.jl/stable/manual/nlp/#Nonlinear-Modeling.\n",
    "\n",
    "Note that nonlinear expressions do not support linear algebra currently.\n",
    "\n",
    "Development is currently underway to overhaul the entire nonlinear interface and remove the need for `@NLexpression` and its limitations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "We have already seen how to set linear/quadratic objectives using `@objective`. Let's learn a little more.\n",
    "\n",
    "### Modification\n",
    "Once an objective is set, we can modify by simply calling `@objective` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to play with\n",
    "model = Model()\n",
    "@variable(model, x[1:2])\n",
    "@variable(model, y[1:3])\n",
    "\n",
    "# Set objective\n",
    "@objective(model, Min, 2x[1] + 3x[2])\n",
    "@show objective_function(model)\n",
    "\n",
    "# Change the objective\n",
    "@objective(model, Min, 4x[1] + 3x[2])\n",
    "@show objective_function(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all we want to do is change a linear coefficient, then we can use `set_objective_coefficient` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_objective_coefficient(model, x[1], 2)\n",
    "objective_function(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Objectives\n",
    "In analogous manner to expressions, non-quadratic/affine objectives must be specified via `@NLobjective`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@NLobjective(model, Min, log(x[1]) + x[2]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These incur the same limitations as `@NLexpression` and will be reworked with the current overhaul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Linear Algebra Objective\n",
    "**Problem**\n",
    "- Create a quadratic objective\n",
    "- The function is $x^T A y + b^T y + c^Tx$\n",
    "- Maximize the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1 3 6; -9 2 1]\n",
    "b = [3, -2, 0]\n",
    "c = [2, 1]\n",
    "\n",
    "# PUT CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "Previously, we saw how to add simple scalar constraints. We will now take a deeper dive into using constraints in `JuMP.jl`.\n",
    "\n",
    "Let's setup a model and variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, x[1:2])\n",
    "J = 2:3 # define a set-like index object\n",
    "@variable(model, y[J]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymous Constraints\n",
    "Commonly, we can declare constraints with names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, c1, x[1] + 2x[2] >= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds a constraint to `model` with the name `\"c1\"` and creates a Julia variable `c1` that contains a constraint reference which points to the constraint in the model. It also registers the Julia variable such that the constraint can be accessed via `model[:c1]` just like what happens with variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show model[:c1]\n",
    "@show c1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to, we can omit the name argument and make an anonymous constraint which is not registered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = @constraint(model, x[1] + 2x[2] >= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we don't have to name every constraint if we don't want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint Abstraction\n",
    "Constraints in `JuMP` (which are stored in the `MOI` backend) are stored with the form `function` in `set`. Here `function` can be any scalar/vector-valued algebraic expression and `set` describes the constraint placed on the expression. For instance, let's consider the linear constraint $x_1 + 2x_2 \\geq 42$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, c2, x[1] + 2x[2] >= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interrogate the `function` and the `set`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_constr = constraint_object(c1)\n",
    "@show jump_function(raw_constr)\n",
    "@show moi_set(raw_constr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have a linear expression $x_1 + 2x_2$ and a constraint set $\\geq 42$ which constrains the expression to be greater than 42. If we were so inclined, we could directly express the constraint this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, x[1] + 2x[2] in MOI.GreaterThan(42.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about all the sets that `MOI` supports see https://jump.dev/JuMP.jl/stable/moi/manual/constraints/#Constraints-by-function-set-pairs. We will keep the remainder of the discussion to the symbolic forms that `JuMP` provides which conveniently wrap around these underlying sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key consequence of this modeling abstraction is that `JuMP` *normalizes* constraints, moving variables to the right-hand side and moving constants to the left-hand side. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, 2x[1] + 1 <= 4x[1] + 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint Senses\n",
    "Here we review the symbolic senses supported by `@constraint`. We illustrate these below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, 4 <= 2 * x[2] <= 5)            # `lb <= expr <= ub` interval     (can also use `≤`)\n",
    "@constraint(model, sum(x) <= 1)                   # `<=`               less than    (can also use `≤`)\n",
    "@constraint(model, x[1] + 2 * x[2] >= 2)          # `>=`               greater than (can also use `≥`)\n",
    "@constraint(model, sum(j * y[j] for j in J) == 3) # `==`               equal to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the vectorized version of these operators by adding a `.` in front of the operator. This is often useful with linear algebra definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1 2; 3 4]\n",
    "b = [5, 6]\n",
    "\n",
    "@constraint(model, A * x .== b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can help write some very compact formulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Sets/Containers\n",
    "In similar manner to expressions and variables, we can create collections of constraints using `JuMP` containers. For instance, consider the constraint $x_i^2 + 4y_j \\leq 0, \\ i \\in \\{1, 2\\}, j \\in J$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, my_constr[i ∈ 1:2, j ∈ J], x[i]^2 + 4y[j] ≤ 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the name `my_constr` is optional and instead of `in` we used `∈`. Here the supported index syntax is exactly the same as `@variable`, in fact all the `JuMP` macros use the same syntax. We can access individual constraints by indexing the container we generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_constr[2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This syntax is very flexible and can accommodate a wide variety of indexing schemes in native Julia code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Arc Constraints\n",
    "**Problem**\n",
    "- Define constraints of form $2x_i + y_j = 0, \\ (i, j) \\in A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [(1, 2), (2, 3), (2, 2)]\n",
    "\n",
    "# PUT CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification\n",
    "That are several ways to modify constraints. We will highlight a few.\n",
    "\n",
    "Recall that all constants are moved to the RHS. We can modify the RHS of a constraint via `set_normalized_rhs`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = @constraint(model, 2x[1] <= 1)\n",
    "@show con \n",
    "set_normalized_rhs(con, 3)\n",
    "@show con;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change the coefficient of a linear variable via `set_normalized_coefficient`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show con \n",
    "set_normalized_coefficient(con, x[1], -1)\n",
    "@show con;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also delete constraints via `delete`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete(model, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Constraints\n",
    "We will now highlight other constraint types that are natively supported by `JuMP`.\n",
    "\n",
    "First, consider second-order cone constraints $||x||_2 \\leq t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, t)\n",
    "@variable(model, x[1:2])\n",
    "@constraint(model, [t; x] in SecondOrderCone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, rotated second order cone constraints $||x||_2^2 \\leq 2t \\cdot u$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, t)\n",
    "@variable(model, u)\n",
    "@variable(model, x[1:2])\n",
    "@constraint(model, [t; u; x] in RotatedSecondOrderCone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, semi-continuous variables $y \\in \\{0\\} \\cup [l, u]$ and semi-integer variables $z \\in \\{0\\} \\cup [l, l + 1, \\dots, u]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, y)\n",
    "@constraint(model, y in MOI.Semicontinuous(1.5, 3.5))\n",
    "@variable(model, z)\n",
    "@constraint(model, z in MOI.Semiinteger(1.0, 3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, special ordered sets of type 1 (SOS1) and SOS2 constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, v[1:3])\n",
    "@constraint(model, v in SOS1())\n",
    "@constraint(model, v in SOS2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, indicator constraints where a linear constraint is enforced when a binary variable is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, a, Bin)\n",
    "@constraint(model, a => {y + z <= 1})\n",
    "@constraint(model, !a => {z >= 3}) # inverted logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, positive-semi definite (PSD) constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, X[1:2, 1:2])\n",
    "@constraint(model, X >= 0, PSDCone()) # note it is preferred to define as `@variable(X[1:2, 1:2], PSD)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll mention complementarity constraints $F(s) \\perp s$ with $s \\in [lb, ub]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, 0 <= s <= 1)\n",
    "@constraint(model, 2s - 1 ⟂ s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also note that constraint programming constraints are coming soon (there are pending pull requests)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Constraints\n",
    "Nonlinear constraints (anything with non-affine/quadratic expressions) are defined via `@NLconstraint`. These follow the same syntax as `@NLexpression` except they accept constraint senses `<=`, `==`, and `>=`. For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@NLconstraint(model, sin(s)^3 + 42 / s <= cos(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define a container of nonlinear constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@NLconstraint(model, [i ∈ 1:2], sum(exp(x[i]^3.2) for i in 1:2) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that nonlinear constraints currently come with limitations:\n",
    "- Linear algebra is not supported\n",
    "- Vectorized calls are not supported\n",
    "- Vector constraints and other specialized constraints are not supported\n",
    "\n",
    "The ongoing modernization of the nonlinear interface will rectify these limitations and eliminate the need for `@NLconstraint`. \n",
    "\n",
    "**Note**: When possible use `@constraint` instead of `@NLconstraint` for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "We have already reviewed the common query methods which include:\n",
    "- `termination_status`\n",
    "- `primal_status`\n",
    "- `dual_status`\n",
    "- `objective_value`\n",
    "- `value`\n",
    "- `shadow_price`\n",
    "\n",
    "Here we will take closer look and review a few more of the available methods.\n",
    "\n",
    "Let's first setup an optimized model that we can query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "set_silent(model)\n",
    "@variable(model, x >= 0)\n",
    "@variable(model, y[[:a, :b]] <= 1)\n",
    "@objective(model, Max, -12x - 20y[:a])\n",
    "@expression(model, my_expr, 6x + 8y[:a])\n",
    "@constraint(model, my_expr >= 100)\n",
    "@constraint(model, c1, 7x + 12y[:a] >= 120)\n",
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Summary\n",
    "For a general overview, we can use `solution_summary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get even more information if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_summary(model, verbose=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Termination Status\n",
    "We already discussed querying the statuses which are independent of the solver used. We can also extract the raw status as report by the solver via `raw_status`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_status(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primal Solutions\n",
    "Before querying values, we should always check that there are some we can actually get via `has_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_values(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query the value of a container of a variable/expression/constraint collection, we broadcast over `value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a container with the same indices that contains the optimal values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual Solutions\n",
    "We can check if there are duals to query via `has_duals`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_duals(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the dual objective value via `dual_objective_value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_objective_value(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the dual solution via `dual`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or get the duals of the variable bound via `LowerBoundRef`, `UpperBoundRef`, or `FixRef`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show dual(LowerBoundRef(x))\n",
    "@show dual.(UpperBoundRef.(y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should note that `JuMP`'s definition of dual depends on the constraint direction, not the objective sense (different from some linear programming conventions). If we want the other convention, we can use `shadow_price` and `reduced_cost` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show shadow_price(c1)\n",
    "@show reduced_cost(x)\n",
    "@show reduced_cost.(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Queries\n",
    "Some other attributes we can query are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show solve_time(model)\n",
    "@show relative_gap(model)\n",
    "@show simplex_iterations(model)\n",
    "@show barrier_iterations(model)\n",
    "@show node_count(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other things we can do which are beyond the scope of today include:\n",
    "- Linear sensitivity analysis via `lp_sensitivity_report`\n",
    "- Conflict analysis for infeasible models via `compute_conflict!`\n",
    "- Feasibility checking via `primal_feasibility_report`\n",
    "- For solver that return multiple solutions, we can use the `result` keyword to get the one we want\n",
    "\n",
    "For more information see https://jump.dev/JuMP.jl/stable/manual/solutions/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Functionalities\n",
    "Without going into too much detail we'll mention some other things `JuMP` can do.\n",
    "\n",
    "### Plural Macros\n",
    "Instead of having many individual calls to macros like `@variable`/`@constraint`, we can use the plural version by adding an `s` at the end. For example, for variables we can use `@variables`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "@variables(model, begin\n",
    "    x\n",
    "    y[i=1:2] >= i, (start = i, base_name = \"Y_$i\")\n",
    "    z, Bin\n",
    "end)\n",
    "\n",
    "latex_formulation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver-Independent Callbacks\n",
    "Callbacks can be powerful ways to modify the way optimization problems are solved. Typically, this is solver dependent, but `JuMP` provides a solver-independent API. In particular, three types of callbacks are supported:\n",
    "- lazy constraints\n",
    "- user-cuts\n",
    "- heuristic solutions\n",
    "\n",
    "Note that this is only supported with a few solvers such as CPLEX, GLPK, Gurobi, and Xpress. For details, see https://jump.dev/JuMP.jl/stable/manual/callbacks/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Declaring parameters can a useful way to way the values of constants in a model without having reconstruct the whole thing. For nonlinear expressions/constraints, `JuMP` features the `@NLparameter` macro to define parameters that we can use in nonlinear expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@NLparameter(model, p[i = 1:2] == i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query and update the values via `value` and `set_value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show value.(p)\n",
    "\n",
    "set_value(p[2], 3.0)\n",
    "\n",
    "@show value.(p);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these in any nonlinear expression/objective/constraint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@NLobjective(model, Max, p[1] * x)\n",
    "@NLexpression(model, my_nl_expr, p[1] * x^2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For affine/quadratic expressions/objectives/constraints, we have a few options.\n",
    "\n",
    "First, we can use:\n",
    "- `set_objective_coefficient`\n",
    "- `set_normalized_rhs`\n",
    "- `set_normalized_coefficient`\n",
    "\n",
    "which we have already discussed. \n",
    "\n",
    "If this is not adequate, we can instead use a fixed variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, pvar == 42)\n",
    "\n",
    "ex = @expression(model, pvar * (2x - z))\n",
    "\n",
    "fix(pvar, 10) # change the value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This however introduces an extra variable and does not work with coefficients of quadratic terms. \n",
    "\n",
    "Thus, to overcome these challenges, there are the `ParametricOptInterface.jl` and `ParameterJuMP` extensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "To add to the capabilities of `JuMP`, there are a variety of extension packages:\n",
    "- `StochasticPrograms.jl`: Solve 2-stage stochastic programs\n",
    "- `BilevelJuMP.jl`: Solve bi-level optimization problems\n",
    "- `Coluna.jl`: Implement branch-and-price-and-cut approaches\n",
    "- `Plasmo.jl`: Solve/decompose graph optimization models\n",
    "- `PolyJuMP.jl`: Solve polynomial optimization problems\n",
    "- `SDDP.jl`: Solve multi-stage stochastic problems via SDDP\n",
    "- `SumOfSquares.jl`: Solve polynomial optimization problems\n",
    "- `vOptGeneric.jl`: Multi-objective optimization\n",
    "- `InfiniteOpt.jl`: Solve infinite-dimensional optimization problems\n",
    "- `DisjunctiveProgramming.jl`: Solve GDP problems\n",
    "\n",
    "We'll focus today on `InfiniteOpt.jl`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
