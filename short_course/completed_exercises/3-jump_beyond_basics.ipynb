{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `JuMP.jl`: Beyond the Basics\n",
    "In the first part of our `JuMP.jl` introduction, we learned how to model/solve simple optimization problems with scalar decision variables. In this part, we take a deeper dive into `JuMP.jl`'s features and to have the tools we need to tackle real problems.\n",
    "\n",
    "## Resources\n",
    "Again, for reference, here are resources to learn more and get help:\n",
    "- The tutorials, examples, manuals, and guides in `JuMP.jl`'s documentation: https://jump.dev/JuMP.jl/stable/\n",
    "- The Julia optimization forum: https://discourse.julialang.org/c/domain/opt/13\n",
    "- Julia Programming for Operations Research 2/e (not always up-to-date): https://www.softcover.io/read/7b8eb7d0/juliabook2/introduction\n",
    "\n",
    "## Models and Solvers\n",
    "We have learned how to create `Model` objects with an optimizer using its default settings. Now let's take a closer look.\n",
    "\n",
    "### Solver Specification\n",
    "As before, we can create by passing an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A JuMP Model\n",
       "Feasibility problem with:\n",
       "Variables: 0\n",
       "Model mode: AUTOMATIC\n",
       "CachingOptimizer state: EMPTY_OPTIMIZER\n",
       "Solver name: HiGHS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using JuMP, HiGHS\n",
    "\n",
    "model = Model(HiGHS.Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can create the `Model` add the optimizer later (any time before calling `optimize!`) via `set_optimizer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "set_optimizer(model, HiGHS.Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all allows us to create a `Model` object and attach a solver to it. However, where possible the optimizer should be provided directly to the `Model` object for better error messaging (e.g., adding a constraint that the solver doesn't support). \n",
    "\n",
    "Often times we may wish to specify options (attributes) to the solver. One way to accomplish this is via `optimizer_with_attributes`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A JuMP Model\n",
       "Feasibility problem with:\n",
       "Variables: 0\n",
       "Model mode: AUTOMATIC\n",
       "CachingOptimizer state: EMPTY_OPTIMIZER\n",
       "Solver name: HiGHS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model(optimizer_with_attributes(HiGHS.Optimizer, \"output_flag\" => false, \"presolve\" => \"on\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the attributes are solver specific and can be found by checking the documentation associated with each solver. We can also specify/modify attributes using `set_optimizer_attribute`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "set_optimizer_attribute(model, \"output_flag\", false)\n",
    "set_optimizer_attribute(model, \"presolve\", \"on\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, `JuMP.jl` provides a few solver-agnostic methods for setting common attributes such as turning the output off and setting a time limit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "set_silent(model) # turn the output printing off\n",
    "set_time_limit_sec(model, 60.0) # set a time limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Writing/Reading\n",
    "`JuMP.jl` does support writing models to files via `write_to_file` and creating a model from a file via `read_from_file`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A JuMP Model\n",
       "Minimization problem with:\n",
       "Variables: 0\n",
       "Objective function type: AffExpr\n",
       "Model mode: AUTOMATIC\n",
       "CachingOptimizer state: NO_OPTIMIZER\n",
       "Solver name: No optimizer attached."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write_to_file(model, \"model.mps\")\n",
    "read_model = read_from_file(\"model.mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on supported files and details about this refer to https://jump.dev/JuMP.jl/stable/manual/models/#Write-a-model-to-file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MathOptInterface.jl` Backends and Performance\n",
    "More advanced users may wish to better understand what is going on behind the scenes and squeeze out some better performance. This section will touch upon some of these considerations at a surface level. A more throughout discussion is provided at https://jump.dev/JuMP.jl/stable/manual/models/#Backends\n",
    "\n",
    "`JuMP.jl` `Model`s are thin wrappers `MathOptInterface.jl` models which are what actually store the optimization problem and interface to the solvers. These model(s) employed by `MathOptInterface.jl` behind the scenes are called the backend and can be accessed via `backend`. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MOIU.CachingOptimizer{MOIB.LazyBridgeOptimizer{HiGHS.Optimizer}, MOIU.UniversalFallback{MOIU.Model{Float64}}}\n",
       "in state EMPTY_OPTIMIZER\n",
       "in mode AUTOMATIC\n",
       "with model cache MOIU.UniversalFallback{MOIU.Model{Float64}}\n",
       "  fallback for MOIU.Model{Float64}\n",
       "with optimizer MOIB.LazyBridgeOptimizer{HiGHS.Optimizer}\n",
       "  with 0 variable bridges\n",
       "  with 0 constraint bridges\n",
       "  with 0 objective bridges\n",
       "  with inner model A HiGHS model with 0 columns and 0 rows."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "b = backend(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is quite a bit going on here in addition to the `MOI` `HiGHS.Optimizer` model. We'll briefly describe these different layers. \n",
    "\n",
    "The `MOIU.CachingOptimizer` is a layer that allows us to build models incrementally (e.g., adding variables one by one) even if the solver doesn't support that. All the information is stored in `MOIU.UniversalFallback{MOIU.Model{Float64}}` which acts as a cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MOIU.UniversalFallback{MOIU.Model{Float64}}\n",
       "fallback for MOIU.Model{Float64}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.model_cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cache model can always be build/modified incrementally. This is then used to efficiently update the optimizer model `MOIB.LazyBridgeOptimizer{HiGHS.Optimizer}` when appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MOIB.LazyBridgeOptimizer{HiGHS.Optimizer}\n",
       "with 0 variable bridges\n",
       "with 0 constraint bridges\n",
       "with 0 objective bridges\n",
       "with inner model A HiGHS model with 0 columns and 0 rows."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the optimizer model (`HiGHS.Optimizer`) is wrapped in `MOIB.LazyBridgeOptimizer`. The bridge layer allows constraints to be transformed (i.e., bridged) to forms that a solver supports. For example, we might need to split an interval constraint into 2 inequality constraints.\n",
    "\n",
    "If constraint bridges are unnecessary for our model, and we wish to decrease the start-up latency, we can use `add_bridges = false` when we create the `JuMP.jl` `Model` to eliminate this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MOIU.CachingOptimizer{HiGHS.Optimizer, MOIU.UniversalFallback{MOIU.Model{Float64}}}\n",
       "in state EMPTY_OPTIMIZER\n",
       "in mode AUTOMATIC\n",
       "with model cache MOIU.UniversalFallback{MOIU.Model{Float64}}\n",
       "  fallback for MOIU.Model{Float64}\n",
       "with optimizer A HiGHS model with 0 columns and 0 rows."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model(HiGHS.Optimizer; add_bridges = false)\n",
    "backend(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `MOIB.LazyBridgeOptimizer` layer on the optimizer is now gone. \n",
    "\n",
    "To take this a step further, we can eliminate the cache model entirely by creating a model via `direct_model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A HiGHS model with 0 columns and 0 rows."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = direct_model(HiGHS.Optimizer())\n",
    "backend(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only have the `HiGHS.Optimizer` as the backend model. This avoids the overhead of the caching model which effectively creates two copies of our model. However, there are a few caveats:\n",
    "- This will not work for solvers that cannot be build incrementally (e.g., Ipopt)\n",
    "- There are no bridges to reformulate constraints into acceptable forms\n",
    "- The behavior of querying the solution after modification to the problem is solver specific\n",
    "\n",
    "So direct models can help increase performance, but should be used carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "Let's take a deeper dive into more of the things we can do with `@variable`.\n",
    "\n",
    "### Containers and Sets\n",
    "We have already seen how to add individual scalar variables, now let's see how to add multiple variables at once.\n",
    "\n",
    "`JuMP.jl` uses 3 data structures to store variable collections:\n",
    "- `Array`s: The native Julia arrays\n",
    "- `DenseAxisArray`s: Dense arrays with arbitrary indices\n",
    "- `SparseAxisArray`s: Sparse arrays with arbitrary indices\n",
    "\n",
    "Arrays are created using integer indices of the form `1:n`. For instance, the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×4 Matrix{VariableRef}:\n",
       " a[1,1]  a[1,2]  a[1,3]  a[1,4]\n",
       " a[2,1]  a[2,2]  a[2,3]  a[2,4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "@variable(model, a[1:2, 1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a 2 x 4 matrix of variables that is stored to `a` which we can index and use in defining our problem.\n",
    "\n",
    "We can also create an n-dimensional vector variable $x \\in \\mathbb{R}^n$ with upper and lower bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{VariableRef}:\n",
       " x[1]\n",
       " x[2]\n",
       " x[3]\n",
       " x[4]\n",
       " x[5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 5\n",
    "l = [1, 2, 3, 4, 5]\n",
    "u = [10, 11, 12, 13, 14]\n",
    "\n",
    "@variable(model, l[i] <= x[i = 1:n] <= u[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we declare an index `i` to help us define the appropriate values. \n",
    "\n",
    "We can use other index forms that don't conform to `1:n` and make `DenseAxisArray`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-dimensional DenseAxisArray{VariableRef,2,...} with index sets:\n",
       "    Dimension 1, 2:3\n",
       "    Dimension 2, 1:2:3\n",
       "And data, a 2×2 Matrix{VariableRef}:\n",
       " z[2,1]  z[2,3]\n",
       " z[3,1]  z[3,3]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, z[i = 2:3, j = 1:2:3] >= i + 2j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't even have to use integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-dimensional DenseAxisArray{VariableRef,2,...} with index sets:\n",
       "    Dimension 1, [\"red\", \"blue\"]\n",
       "    Dimension 2, Base.OneTo(5)\n",
       "And data, a 2×5 Matrix{VariableRef}:\n",
       " w[red,1]   w[red,2]   w[red,3]   w[red,4]   w[red,5]\n",
       " w[blue,1]  w[blue,2]  w[blue,3]  w[blue,4]  w[blue,5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, w[[\"red\", \"blue\"], 1:5] <= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For indices that do not form a rectangular set, a `SparseAxisArray` is formed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JuMP.Containers.SparseAxisArray{VariableRef, 2, Tuple{Int64, Int64}} with 5 entries:\n",
       "  [1, 1]  =  u[1,1]\n",
       "  [1, 2]  =  u[1,2]\n",
       "  [1, 3]  =  u[1,3]\n",
       "  [2, 2]  =  u[2,2]\n",
       "  [2, 3]  =  u[2,3]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, u[i = 1:2, j = i:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even add a conditional statement after a `;` when defining indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JuMP.Containers.SparseAxisArray{VariableRef, 2, Tuple{Int64, Int64}} with 6 entries:\n",
       "  [1, 1]  =  v[1,1]\n",
       "  [1, 2]  =  v[1,2]\n",
       "  [1, 3]  =  v[1,3]\n",
       "  [2, 1]  =  v[2,1]\n",
       "  [2, 2]  =  v[2,2]\n",
       "  [3, 1]  =  v[3,1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, v[i = 1:3, j = 1:4; i + j <= 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrality\n",
    "To specify integer variables, we need only add the `Int` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ integer\\_x $"
      ],
      "text/plain": [
       "integer_x"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, integer_x, Int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by setting `integer = true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ integer\\_z $"
      ],
      "text/plain": [
       "integer_z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, integer_z, integer = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we create binary variables via the `Bin` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ binary\\_x $"
      ],
      "text/plain": [
       "binary_x"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, binary_x, Bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or by using `binary = true`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ binary\\_z $"
      ],
      "text/plain": [
       "binary_z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, binary_z, binary = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Nodal Variables\n",
    "**Problem**\n",
    "- Create a variable named `xp`\n",
    "- `xp` should be integer valued between 0 and 3\n",
    "- `xp` should be indexed over each arc `(i, j)` in `arcs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-dimensional DenseAxisArray{VariableRef,1,...} with index sets:\n",
       "    Dimension 1, [(1, 2), (1, 3), (3, 2), (2, 4)]\n",
       "And data, a 4-element Vector{VariableRef}:\n",
       " xp[(1, 2)]\n",
       " xp[(1, 3)]\n",
       " xp[(3, 2)]\n",
       " xp[(2, 4)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arcs = [(1, 2), (1, 3), (3, 2), (2, 4)]\n",
    "\n",
    "# PUT CODE HERE\n",
    "@variable(model, 0 ≤ xp[(i, j) ∈ arcs] ≤ 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Options\n",
    "There are a variety of other things we can do with variables. We can create a fixed variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ x\\_fixed $"
      ],
      "text/plain": [
       "x_fixed"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, x_fixed == 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the initial guess to pass on to the solver via `start`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ q $"
      ],
      "text/plain": [
       "q"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, q, start = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify lower/upper bounds via the keyword arguments `lower_bound` and `upper_bound`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymous Variables\n",
    "Normally when we create variables they are registered in the model, so we can access them via `model[:var_name]`. For instance, consider a typical definition of a scalar variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ x $"
      ],
      "text/plain": [
       "x"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "@variable(model, x >= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does a few things:\n",
    "- Add a scalar variable with a name `\"x\"` to `model`\n",
    "- Add a lower bound of 0\n",
    "- Create a Julia variable `x` that stores a reference to the optimization variable\n",
    "- Registers that Julia variable in `model` such that is can be accessed via `model[:x]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = x\n",
      "model[:x] = x\n"
     ]
    }
   ],
   "source": [
    "@show x \n",
    "@show model[:x];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this registration means we cannot add another variable with the same name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "An object of name x is already attached to this model. If this\n    is intended, consider using the anonymous construction syntax, for example,\n    `x = @variable(model, [1:N], ...)` where the name of the object does\n    not appear inside the macro.\n\n    Alternatively, use `unregister(model, :x)` to first unregister\n    the existing name from the model. Note that this will not delete the\n    object; it will just remove the reference at `model[:x]`.\n",
     "output_type": "error",
     "traceback": [
      "An object of name x is already attached to this model. If this\n",
      "    is intended, consider using the anonymous construction syntax, for example,\n",
      "    `x = @variable(model, [1:N], ...)` where the name of the object does\n",
      "    not appear inside the macro.\n",
      "\n",
      "    Alternatively, use `unregister(model, :x)` to first unregister\n",
      "    the existing name from the model. Note that this will not delete the\n",
      "    object; it will just remove the reference at `model[:x]`.\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] error(s::String)\n",
      "   @ Base .\\error.jl:35\n",
      " [2] _error_if_cannot_register(model::Model, name::Symbol)\n",
      "   @ JuMP C:\\Users\\Pulsipher\\.julia\\packages\\JuMP\\7rBNn\\src\\macros.jl:411\n",
      " [3] macro expansion\n",
      "   @ C:\\Users\\Pulsipher\\.julia\\packages\\JuMP\\7rBNn\\src\\macros.jl:400 [inlined]\n",
      " [4] top-level scope\n",
      "   @ c:\\Users\\Pulsipher\\Documents\\InfiniteOptTutorials\\short_course\\completed_exercises\\3-jump_beyond_basics.ipynb:1"
     ]
    }
   ],
   "source": [
    "@variable(model, x == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this behavior is prohibitive, we can define an anonymous variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ x $"
      ],
      "text/plain": [
       "x"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = @variable(model, lower_bound = 0, base_name = \"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds an optimization variable to the model with a lower bound and name `\"x\"`, but doesn't register it. We store the resulting variable reference in the Julia variable `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Variables\n",
    "There are a variety of ways to change variables after they are created. Some common methods include:\n",
    "- `set_lower_bound`\n",
    "- `set_upper_bound`\n",
    "- `fix`\n",
    "- `set_start_value`\n",
    "- `set_binary`\n",
    "- `set_integer`\n",
    "- `delete`\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_upper_bound(x, 10)\n",
    "set_integer(x)\n",
    "delete(model, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more things we can do, see https://jump.dev/JuMP.jl/stable/manual/variables/ to learn more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressions\n",
    "Sometimes we may want to use a mathematical expression in multiple constraints and/or the objective. We can create expressions using `@expression`. To motivate this, let's create a model with variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, x[1:2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressions\n",
    "We can create expressions using `@expression`. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ x_{1}^2 - 3 x_{2} $"
      ],
      "text/plain": [
       "x[1]² - 3 x[2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_expr = @expression(model, x[1]^2 - 3x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates an anonymous expression that we can use elsewhere. We can also create named/registered expressions by adding a name argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_expr = x[1]² - 3 x[2]\n"
     ]
    }
   ],
   "source": [
    "@expression(model, my_expr, x[1]^2 - 3x[2])\n",
    "@show my_expr;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a Julia variable `my_expr` to access the expression and registers it, so we can get it by indexing `model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ x_{1}^2 - 3 x_{2} $"
      ],
      "text/plain": [
       "x[1]² - 3 x[2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model[:my_expr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a container of expressions, just like we can for variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{QuadExpr}:\n",
       " 4 x[1]²\n",
       " 4 x[2]²"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@expression(model, expr[i = 1:2], 4x[i]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra\n",
    "For linear/quadratic expressions, `JuMP.jl` supports linear algebra operations. For instance, consider $x^T A y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ y_{1}\\times x_{1} + 2 y_{1}\\times x_{2} + 2 y_{2}\\times x_{1} + 6 y_{2}\\times x_{2} + 4 y_{3}\\times x_{1} + y_{3}\\times x_{2} $"
      ],
      "text/plain": [
       "y[1]*x[1] + 2 y[1]*x[2] + 2 y[2]*x[1] + 6 y[2]*x[2] + 4 y[3]*x[1] + y[3]*x[2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, y[1:3])\n",
    "A = [1 2 4; 2 6 1]\n",
    "\n",
    "@expression(model, x' * A * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ x_{1}\\times y_{1} + 2 y_{1}\\times x_{2} + 2 y_{2}\\times x_{1} + 6 y_{2}\\times x_{2} + 4 y_{3}\\times x_{1} + y_{3}\\times x_{2} $"
      ],
      "text/plain": [
       "x[1]*y[1] + 2 y[1]*x[2] + 2 y[2]*x[1] + 6 y[2]*x[2] + 4 y[3]*x[1] + y[3]*x[2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@expression(model, sum(x[i] * A[i, j] * y[j] for j in 1:3, i in 1:2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Expressions\n",
    "Any nonlinear expressions are also defined via `@expression`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{NonlinearExpr}:\n",
       " 2.0 * sin(x[1])\n",
       " 2.0 * sin(x[2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@expression(model, nlexpr[i = 1:2], 2sin(x[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library of built-in univariate operators is derived those listed in `MOI.ListOfSupportedNonlinearOperators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86-element Vector{Symbol}:\n",
       " :+\n",
       " :-\n",
       " :abs\n",
       " :sign\n",
       " :sqrt\n",
       " :cbrt\n",
       " :abs2\n",
       " :inv\n",
       " :log\n",
       " :log10\n",
       " ⋮\n",
       " :min\n",
       " :max\n",
       " :&&\n",
       " :||\n",
       " :<=\n",
       " :(==)\n",
       " :>=\n",
       " :<\n",
       " :>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Ipopt\n",
    "\n",
    "MOI.get(Ipopt.Optimizer(), MOI.ListOfSupportedNonlinearOperators())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use some other nonlinear operator that is not natively supported, we can add our own! For instance, let's add the `logerfcx` from `SpecialFunctions.jl` using `@operator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{NonlinearExpr}:\n",
       " op_logerfcx(x[1])\n",
       " op_logerfcx(x[2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using SpecialFunctions\n",
    "\n",
    "@operator(model, op_logerfcx, 1, logerfcx) # register a univariate operator `op_logerfcx` and use auto differientiation for gradients\n",
    "@expression(model, [i = 1:2], op_logerfcx(x[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on nonlinear expressions see https://jump.dev/JuMP.jl/stable/manual/nonlinear/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "We have already seen how to set linear/quadratic objectives using `@objective`. Let's learn a little more.\n",
    "\n",
    "### Modification\n",
    "Once an objective is set, we can modify by simply calling `@objective` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective_function(model) = log(x[1]) + (x[2]²)\n",
      "objective_function(model) = 4 x[1] + 3 x[2]\n"
     ]
    }
   ],
   "source": [
    "# Model to play with\n",
    "model = Model()\n",
    "@variable(model, x[1:2])\n",
    "@variable(model, y[1:3])\n",
    "\n",
    "# Set objective\n",
    "@objective(model, Min, log(x[1]) + x[2]^2)\n",
    "@show objective_function(model)\n",
    "\n",
    "# Change the objective\n",
    "@objective(model, Min, 4x[1] + 3x[2])\n",
    "@show objective_function(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all we want to do is change a linear coefficient, then we can use `set_objective_coefficient` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ 2 x_{1} + 3 x_{2} $"
      ],
      "text/plain": [
       "2 x[1] + 3 x[2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_objective_coefficient(model, x[1], 2)\n",
    "objective_function(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Linear Algebra Objective\n",
    "**Problem**\n",
    "- Create a quadratic objective\n",
    "- The function is $x^T A y + b^T y + c^Tx$\n",
    "- Maximize the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ y_{1}\\times x_{1} - 9 y_{1}\\times x_{2} + 3 y_{2}\\times x_{1} + 2 y_{2}\\times x_{2} + 6 y_{3}\\times x_{1} + y_{3}\\times x_{2} + 3 y_{1} - 2 y_{2} + 2 x_{1} + x_{2} $"
      ],
      "text/plain": [
       "y[1]*x[1] - 9 y[1]*x[2] + 3 y[2]*x[1] + 2 y[2]*x[2] + 6 y[3]*x[1] + y[3]*x[2] + 3 y[1] - 2 y[2] + 2 x[1] + x[2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = [1 3 6; -9 2 1]\n",
    "b = [3, -2, 0]\n",
    "c = [2, 1]\n",
    "\n",
    "# PUT CODE HERE\n",
    "@objective(model, Min, x' * A * y + b' * y + c' * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "Previously, we saw how to add simple scalar constraints. We will now take a deeper dive into using constraints in `JuMP.jl`.\n",
    "\n",
    "Let's setup a model and variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "@variable(model, x[1:2])\n",
    "J = 2:3 # define a set-like index object\n",
    "@variable(model, y[J]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymous Constraints\n",
    "Commonly, we can declare constraints with names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ x_{1} + 2 x_{2} \\geq 42 $$"
      ],
      "text/plain": [
       "c1 : x[1] + 2 x[2] >= 42"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@constraint(model, c1, x[1] + 2x[2] >= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds a constraint to `model` with the name `\"c1\"` and creates a Julia variable `c1` that contains a constraint reference which points to the constraint in the model. It also registers the Julia variable such that the constraint can be accessed via `model[:c1]` just like what happens with variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model[:c1] = c1 : x[1] + 2 x[2] >= 42\n",
      "c1 = c1 : x[1] + 2 x[2] >= 42\n"
     ]
    }
   ],
   "source": [
    "@show model[:c1]\n",
    "@show c1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to, we can omit the name argument and make an anonymous constraint which is not registered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ x_{1} + 2 x_{2} \\geq 42 $$"
      ],
      "text/plain": [
       "x[1] + 2 x[2] >= 42"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1 = @constraint(model, x[1] + 2x[2] >= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we don't have to name every constraint if we don't want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint Abstraction\n",
    "Constraints in `JuMP` (which are stored in the `MOI` backend) are stored with the form `function` in `set`. Here `function` can be any scalar/vector-valued algebraic expression and `set` describes the constraint placed on the expression. For instance, let's consider the linear constraint $x_1 + 2x_2 \\geq 42$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ x_{1} + 2 x_{2} \\geq 42 $$"
      ],
      "text/plain": [
       "c2 : x[1] + 2 x[2] >= 42"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@constraint(model, c2, x[1] + 2x[2] >= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's interrogate the `function` and the `set`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump_function(raw_constr) = x[1] + 2 x[2]\n",
      "moi_set(raw_constr) = MathOptInterface.GreaterThan{Float64}(42.0)\n"
     ]
    }
   ],
   "source": [
    "raw_constr = constraint_object(c1)\n",
    "@show jump_function(raw_constr)\n",
    "@show moi_set(raw_constr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have a linear expression $x_1 + 2x_2$ and a constraint set $\\geq 42$ which constrains the expression to be greater than 42. If we were so inclined, we could directly express the constraint this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ x_{1} + 2 x_{2} \\geq 42 $$"
      ],
      "text/plain": [
       "x[1] + 2 x[2] >= 42"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@constraint(model, x[1] + 2x[2] in MOI.GreaterThan(42.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about all the sets that `MOI` supports see https://jump.dev/JuMP.jl/stable/moi/manual/constraints/#Constraints-by-function-set-pairs. We will keep the remainder of the discussion to the symbolic forms that `JuMP` provides which conveniently wrap around these underlying sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key consequence of this modeling abstraction is that `JuMP` *normalizes* constraints, moving variables to the right-hand side and moving constants to the left-hand side. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ -2 x_{1} \\leq 3 $$"
      ],
      "text/plain": [
       "-2 x[1] <= 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@constraint(model, 2x[1] + 1 <= 4x[1] + 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint Senses\n",
    "Here we review the symbolic senses supported by `@constraint`. We illustrate these below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ 2 y_{2} + 3 y_{3} = 3 $$"
      ],
      "text/plain": [
       "2 y[2] + 3 y[3] == 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@constraint(model, 4 <= 2 * x[2] <= 5)            # `lb <= expr <= ub` interval     (can also use `≤`)\n",
    "@constraint(model, sum(x) <= 1)                   # `<=`               less than    (can also use `≤`)\n",
    "@constraint(model, x[1] + 2 * x[2] >= 2)          # `>=`               greater than (can also use `≥`)\n",
    "@constraint(model, sum(j * y[j] for j in J) == 3) # `==`               equal to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the vectorized version of these operators by adding a `.` in front of the operator. This is often useful with linear algebra definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{ConstraintRef{Model, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}, ScalarShape}}:\n",
       " x[1] + 2 x[2] == 5\n",
       " 3 x[1] + 4 x[2] == 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = [1 2; 3 4]\n",
    "b = [5, 6]\n",
    "\n",
    "@constraint(model, A * x .== b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can help write some very compact formulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Sets/Containers\n",
    "In similar manner to expressions and variables, we can create collections of constraints using `JuMP` containers. For instance, consider the constraint $x_i^2 + 4y_j \\leq 0, \\ i \\in \\{1, 2\\}, j \\in J$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-dimensional DenseAxisArray{ConstraintRef{Model, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}, ScalarShape},2,...} with index sets:\n",
       "    Dimension 1, Base.OneTo(2)\n",
       "    Dimension 2, 2:3\n",
       "And data, a 2×2 Matrix{ConstraintRef{Model, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarQuadraticFunction{Float64}, MathOptInterface.LessThan{Float64}}, ScalarShape}}:\n",
       " my_constr[1,2] : x[1]² + 4 y[2] <= 0  my_constr[1,3] : x[1]² + 4 y[3] <= 0\n",
       " my_constr[2,2] : x[2]² + 4 y[2] <= 0  my_constr[2,3] : x[2]² + 4 y[3] <= 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@constraint(model, my_constr[i ∈ 1:2, j ∈ J], x[i]^2 + 4y[j] ≤ 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the name `my_constr` is optional and instead of `in` we used `∈`. Here the supported index syntax is exactly the same as `@variable`, in fact all the `JuMP` macros use the same syntax. We can access individual constraints by indexing the container we generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ x_{2}^2 + 4 y_{3} \\leq 0 $$"
      ],
      "text/plain": [
       "my_constr[2,3] : x[2]² + 4 y[3] <= 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_constr[2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This syntax is very flexible and can accommodate a wide variety of indexing schemes in native Julia code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Arc Constraints\n",
    "**Problem**\n",
    "- Define constraints of form $2x_i + y_j = 0, \\ (i, j) \\in A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-dimensional DenseAxisArray{ConstraintRef{Model, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}, ScalarShape},1,...} with index sets:\n",
       "    Dimension 1, [(1, 2), (2, 3), (2, 2)]\n",
       "And data, a 3-element Vector{ConstraintRef{Model, MathOptInterface.ConstraintIndex{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.EqualTo{Float64}}, ScalarShape}}:\n",
       " 2 x[1] + y[2] == 0\n",
       " 2 x[2] + y[3] == 0\n",
       " 2 x[2] + y[2] == 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = [(1, 2), (2, 3), (2, 2)]\n",
    "\n",
    "# PUT CODE HERE\n",
    "@constraint(model, [(i, j) ∈ A], 2x[i] + y[j] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification\n",
    "That are several ways to modify constraints. We will highlight a few.\n",
    "\n",
    "Recall that all constants are moved to the RHS. We can modify the RHS of a constraint via `set_normalized_rhs`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "con = 2 x[1] <= 1\n",
      "con = 2 x[1] <= 3\n"
     ]
    }
   ],
   "source": [
    "con = @constraint(model, 2x[1] <= 1)\n",
    "@show con \n",
    "set_normalized_rhs(con, 3)\n",
    "@show con;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change the coefficient of a linear variable via `set_normalized_coefficient`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "con = 2 x[1] <= 3\n",
      "con = -x[1] <= 3\n"
     ]
    }
   ],
   "source": [
    "@show con \n",
    "set_normalized_coefficient(con, x[1], -1)\n",
    "@show con;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also delete constraints via `delete`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete(model, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Constraints\n",
    "We will now highlight other constraint types that are natively supported by `JuMP`.\n",
    "\n",
    "First, consider second-order cone constraints $||x||_2 \\leq t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ [t, x_{1}, x_{2}] \\in \\text{MathOptInterface.SecondOrderCone(3)} $$"
      ],
      "text/plain": [
       "[t, x[1], x[2]] in MathOptInterface.SecondOrderCone(3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "@variable(model, t)\n",
    "@variable(model, x[1:2])\n",
    "@constraint(model, [t; x] in SecondOrderCone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, rotated second order cone constraints $||x||_2^2 \\leq 2t \\cdot u$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ [t, u, x_{1}, x_{2}] \\in \\text{MathOptInterface.RotatedSecondOrderCone(4)} $$"
      ],
      "text/plain": [
       "[t, u, x[1], x[2]] in MathOptInterface.RotatedSecondOrderCone(4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "@variable(model, t)\n",
    "@variable(model, u)\n",
    "@variable(model, x[1:2])\n",
    "@constraint(model, [t; u; x] in RotatedSecondOrderCone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, semi-continuous variables $y \\in \\{0\\} \\cup [l, u]$ and semi-integer variables $z \\in \\{0\\} \\cup [l, l + 1, \\dots, u]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ z \\in \\text{MathOptInterface.Semiinteger\\{Float64\\}(1.0, 3.0)} $$"
      ],
      "text/plain": [
       "z in MathOptInterface.Semiinteger{Float64}(1.0, 3.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, y)\n",
    "@constraint(model, y in MOI.Semicontinuous(1.5, 3.5))\n",
    "@variable(model, z)\n",
    "@constraint(model, z in MOI.Semiinteger(1.0, 3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, special ordered sets of type 1 (SOS1) and SOS2 constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ [v_{1}, v_{2}, v_{3}] \\in \\text{MathOptInterface.SOS2\\{Float64\\}([1.0, 2.0, 3.0])} $$"
      ],
      "text/plain": [
       "[v[1], v[2], v[3]] in MathOptInterface.SOS2{Float64}([1.0, 2.0, 3.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, v[1:3])\n",
    "@constraint(model, v in SOS1())\n",
    "@constraint(model, v in SOS2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, indicator constraints where a linear constraint is enforced when a binary variable is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ !a --> {z \\geq 3} $$"
      ],
      "text/plain": [
       "!a --> {z >= 3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, a, Bin)\n",
    "@constraint(model, a => {y + z <= 1})\n",
    "@constraint(model, !a => {z >= 3}) # inverted logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, positive-semi definite (PSD) constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{bmatrix}\n",
       "X_{1,1} & X_{1,2}\\\\\n",
       "X_{2,1} & X_{2,2}\\\\\n",
       "\\end{bmatrix} \\in \\text{PSDCone()} $$"
      ],
      "text/plain": [
       "[X[1,1]  X[1,2]\n",
       " X[2,1]  X[2,2]] in PSDCone()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, X[1:2, 1:2])\n",
    "@constraint(model, X >= 0, PSDCone()) # note it is preferred to define as `@variable(X[1:2, 1:2], PSD)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll mention complementarity constraints $F(s) \\perp s$ with $s \\in [lb, ub]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ [2 s - 1, s] \\in \\text{MathOptInterface.Complements(2)} $$"
      ],
      "text/plain": [
       "[2 s - 1, s] in MathOptInterface.Complements(2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, 0 <= s <= 1)\n",
    "@constraint(model, 2s - 1 ⟂ s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also note that constraint programming constraints are also supported: https://jump.dev/JuMP.jl/stable/tutorials/linear/constraint_programming/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "We have already reviewed the common query methods which include:\n",
    "- `termination_status`\n",
    "- `primal_status`\n",
    "- `dual_status`\n",
    "- `objective_value`\n",
    "- `value`\n",
    "- `shadow_price`\n",
    "\n",
    "Here we will take closer look and review a few more of the available methods.\n",
    "\n",
    "Let's first setup an optimized model that we can query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(HiGHS.Optimizer)\n",
    "set_silent(model)\n",
    "@variable(model, x >= 0)\n",
    "@variable(model, y[[:a, :b]] <= 1)\n",
    "@objective(model, Max, -12x - 20y[:a])\n",
    "@expression(model, my_expr, 6x + 8y[:a])\n",
    "@constraint(model, my_expr >= 100)\n",
    "@constraint(model, c1, 7x + 12y[:a] >= 120)\n",
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Summary\n",
    "For a general overview, we can use `solution_summary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* Solver : HiGHS\n",
       "\n",
       "* Status\n",
       "  Result count       : 1\n",
       "  Termination status : OPTIMAL\n",
       "  Message from the solver:\n",
       "  \"kHighsModelStatusOptimal\"\n",
       "\n",
       "* Candidate solution (result #1)\n",
       "  Primal status      : FEASIBLE_POINT\n",
       "  Dual status        : FEASIBLE_POINT\n",
       "  Objective value    : -2.05143e+02\n",
       "  Objective bound    : -0.00000e+00\n",
       "  Relative gap       : Inf\n",
       "  Dual objective value : -2.05143e+02\n",
       "\n",
       "* Work counters\n",
       "  Solve time (sec)   : 9.98020e-04\n",
       "  Simplex iterations : 2\n",
       "  Barrier iterations : 0\n",
       "  Node count         : -1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solution_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get even more information if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* Solver : HiGHS\n",
       "\n",
       "* Status\n",
       "  Result count       : 1\n",
       "  Termination status : OPTIMAL\n",
       "  Message from the solver:\n",
       "  \"kHighsModelStatusOptimal\"\n",
       "\n",
       "* Candidate solution (result #1)\n",
       "  Primal status      : FEASIBLE_POINT\n",
       "  Dual status        : FEASIBLE_POINT\n",
       "  Objective value    : -2.05143e+02\n",
       "  Objective bound    : -0.00000e+00\n",
       "  Relative gap       : Inf\n",
       "  Dual objective value : -2.05143e+02\n",
       "  Primal solution :\n",
       "    x : 1.54286e+01\n",
       "    y[a] : 1.00000e+00\n",
       "    y[b] : 1.00000e+00\n",
       "  Dual solution :\n",
       "    c1 : 1.71429e+00\n",
       "\n",
       "* Work counters\n",
       "  Solve time (sec)   : 9.98020e-04\n",
       "  Simplex iterations : 2\n",
       "  Barrier iterations : 0\n",
       "  Node count         : -1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "solution_summary(model, verbose=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Termination Status\n",
    "We already discussed querying the statuses which are independent of the solver used. We can also extract the raw status as report by the solver via `raw_status`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"kHighsModelStatusOptimal\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_status(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primal Solutions\n",
    "Before querying values, we should always check that there are some we can actually get via `has_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "has_values(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To query the value of a container of a variable/expression/constraint collection, we broadcast over `value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-dimensional DenseAxisArray{Float64,1,...} with index sets:\n",
       "    Dimension 1, [:a, :b]\n",
       "And data, a 2-element Vector{Float64}:\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "value.(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a container with the same indices that contains the optimal values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual Solutions\n",
    "We can check if there are duals to query via `has_duals`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "has_duals(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the dual objective value via `dual_objective_value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-205.1428571428571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dual_objective_value(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the dual solution via `dual`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7142857142857142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dual(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or get the duals of the variable bound via `LowerBoundRef`, `UpperBoundRef`, or `FixRef`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dual(LowerBoundRef(x)) = 0.0\n",
      "dual.(UpperBoundRef.(y)) = 1-dimensional DenseAxisArray{Float64,1,...} with index sets:\n",
      "    Dimension 1, [:a, :b]\n",
      "And data, a 2-element Vector{Float64}:\n",
      " -0.5714285714285694\n",
      "  0.0\n"
     ]
    }
   ],
   "source": [
    "@show dual(LowerBoundRef(x))\n",
    "@show dual.(UpperBoundRef.(y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should note that `JuMP`'s definition of dual depends on the constraint direction, not the objective sense (different from some linear programming conventions). If we want the other convention, we can use `shadow_price` and `reduced_cost` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow_price(c1) = 1.7142857142857142\n",
      "reduced_cost(x) = -0.0\n",
      "reduced_cost.(y) = 1-dimensional DenseAxisArray{Float64,1,...} with index sets:\n",
      "    Dimension 1, [:a, :b]\n",
      "And data, a 2-element Vector{Float64}:\n",
      "  0.5714285714285694\n",
      " -0.0\n"
     ]
    }
   ],
   "source": [
    "@show shadow_price(c1)\n",
    "@show reduced_cost(x)\n",
    "@show reduced_cost.(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Queries\n",
    "Some other attributes we can query are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solve_time(model) = 0.0009980201721191406\n",
      "relative_gap(model) = Inf\n",
      "simplex_iterations(model) = 2\n",
      "barrier_iterations(model) = 0\n",
      "node_count(model) = -1\n"
     ]
    }
   ],
   "source": [
    "@show solve_time(model)\n",
    "@show relative_gap(model)\n",
    "@show simplex_iterations(model)\n",
    "@show barrier_iterations(model)\n",
    "@show node_count(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other things we can do which are beyond the scope of today include:\n",
    "- Linear sensitivity analysis via `lp_sensitivity_report`\n",
    "- Conflict analysis for infeasible models via `compute_conflict!`\n",
    "- Feasibility checking via `primal_feasibility_report`\n",
    "- For solver that return multiple solutions, we can use the `result` keyword to get the one we want\n",
    "\n",
    "For more information see https://jump.dev/JuMP.jl/stable/manual/solutions/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Functionalities\n",
    "Without going into too much detail we'll mention some other things `JuMP` can do.\n",
    "\n",
    "### Plural Macros\n",
    "Instead of having many individual calls to macros like `@variable`/`@constraint`, we can use the plural version by adding an `s` at the end. For example, for variables we can use `@variables`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ \\begin{aligned}\n",
       "\\text{feasibility}\\\\\n",
       "\\text{Subject to} \\quad & Y\\_1_{1} \\geq 1\\\\\n",
       " & Y\\_2_{2} \\geq 2\\\\\n",
       " & z \\in \\{0, 1\\}\\\\\n",
       "\\end{aligned} $$"
      ],
      "text/plain": [
       "$$ \\begin{aligned}\n",
       "\\text{feasibility}\\\\\n",
       "\\text{Subject to} \\quad & Y\\_1_{1} \\geq 1\\\\\n",
       " & Y\\_2_{2} \\geq 2\\\\\n",
       " & z \\in \\{0, 1\\}\\\\\n",
       "\\end{aligned} $$"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "@variables(model, begin\n",
    "    x\n",
    "    y[i=1:2] >= i, (start = i, base_name = \"Y_$i\")\n",
    "    z, Bin\n",
    "end)\n",
    "\n",
    "latex_formulation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver-Independent Callbacks\n",
    "Callbacks can be powerful ways to modify the way optimization problems are solved. Typically, this is solver dependent, but `JuMP` provides a solver-independent API. In particular, three types of callbacks are supported:\n",
    "- lazy constraints\n",
    "- user-cuts\n",
    "- heuristic solutions\n",
    "\n",
    "Note that this is only supported with a few solvers such as CPLEX, GLPK, Gurobi, and Xpress. For details, see https://jump.dev/JuMP.jl/stable/manual/callbacks/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Declaring parameters can a useful way to way the values of constants in a model without having reconstruct the whole thing. This can be accomplished via the `Parameter` set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{VariableRef}:\n",
       " p[1]\n",
       " p[2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@variable(model, p[i = 1:2] in Parameter(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query and update the values via `parameter_value` and `set_parameter_value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter_value.(p) = [1.0, 2.0]\n",
      "parameter_value.(p) = [1.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "@show parameter_value.(p)\n",
    "\n",
    "set_parameter_value(p[2], 3.0)\n",
    "\n",
    "@show parameter_value.(p);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these in any expression/objective/constraint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ {p_{1}} * {\\left(x^2\\right)} $"
      ],
      "text/plain": [
       "p[1] * (x²)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@objective(model, Max, p[1] * x)\n",
    "@expression(model, my_nl_expr, p[1] * x^2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For affine/quadratic expressions/objectives/constraints, we have a few options.\n",
    "\n",
    "First, we can use:\n",
    "- `set_objective_coefficient`\n",
    "- `set_normalized_rhs`\n",
    "- `set_normalized_coefficient`\n",
    "\n",
    "which we have already discussed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "To add to the capabilities of `JuMP`, there are a variety of extension packages:\n",
    "- `StochasticPrograms.jl`: Solve 2-stage stochastic programs\n",
    "- `BilevelJuMP.jl`: Solve bi-level optimization problems\n",
    "- `Coluna.jl`: Implement branch-and-price-and-cut approaches\n",
    "- `Plasmo.jl`: Solve/decompose graph optimization models\n",
    "- `PolyJuMP.jl`: Solve polynomial optimization problems\n",
    "- `SDDP.jl`: Solve multi-stage stochastic problems via SDDP\n",
    "- `SumOfSquares.jl`: Solve polynomial optimization problems\n",
    "- `vOptGeneric.jl`: Multi-objective optimization\n",
    "- `InfiniteOpt.jl`: Solve infinite-dimensional optimization problems\n",
    "- `DisjunctiveProgramming.jl`: Solve GDP problems\n",
    "\n",
    "We'll focus today on `InfiniteOpt.jl`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
