{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `InfiniteOpt.jl`: The Basics\n",
    "Now that we are familiarized with Julia and `JuMP.jl`, let's talk about how `InfiniteOpt.jl` builds upon `JuMP.jl` to allow us to intuitively model infinite-dimensional optimization problems.\n",
    "\n",
    "## Resources\n",
    "Again, there is only so much that we can cover in a tutorial. Helpful resources include:\n",
    "- The documentation: https://pulsipher.github.io/InfiniteOpt.jl/stable/.\n",
    "- The paper: https://www.sciencedirect.com/science/article/pii/S0098135421003458?via%3Dihub \n",
    "- The open-source paper: https://arxiv.org/abs/2106.12689\n",
    "- The `InfiniteOpt.jl` forum: https://github.com/pulsipher/InfiniteOpt.jl/discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Control in `JuMP.jl`\n",
    "To motivate `InfiniteOpt.jl`, let's consider modeling a simple optimal control problem in `JuMP.jl`.\n",
    "\n",
    "### The Formulation\n",
    "We'll take a look at a trajectory control problem:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&&\\underset{x(t), v(t), u(t)}{\\text{min}} &&& \\int_{t \\in \\mathcal{D}_t} ||u(t)||_2^2 dt  \\\\\n",
    "&&\\text{s.t.} &&& \\frac{dx}{dt} = v(t), && t \\in \\mathcal{D}_t\\\\\n",
    "&&&&& \\frac{dv}{dt} = u(t), && t \\in \\mathcal{D}_t\\\\\n",
    "&&&&& x(t) = xw(t), && t \\in \\mathcal{D}_{tw} \\\\\n",
    "&&&&& v(0) = 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "Here position $x(t) \\in \\mathbb{R}^2$ and velocity $v(t) \\in \\mathbb{R}^2$ are state variables. The control variable $u(t) \\in \\mathbb{R}^2$ controls the acceleration (thrust) of the vehicle. Here we wish to plan a path that passes through all the waypoints $xw_i$ and minimizes the thrust used.\n",
    "\n",
    "We cannot directly model this with `JuMP.jl` because the variables are functions of time $t$ and the formulation contains an integrals/derivatives. This is an infinite-dimensional problem.\n",
    "\n",
    "### Discretize\n",
    "We can transform it into a finite optimization `JuMP.jl` can handle by discretizing the variables over time and applying appropriate approximations to the integral/derivatives. \n",
    "\n",
    "We will transform the model via:\n",
    "- let $\\mathcal{D}_t = [0, T]$ and choose $n$ time steps such that $\\Delta t = \\frac{T}{n}$\n",
    "- discretize each infinite variable (e.g., $\\{x_t: t \\in \\{0, 1, \\dots, n\\}$)\n",
    "- replace the integral with a sum over time\n",
    "- approximate the derivatives via implicit Euler\n",
    "\n",
    "With these steps, we obtain:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&&\\underset{x_t, v_t, u_t}{\\text{min}} &&& \\sum_{t \\in \\{1, \\dots, n\\}} u_{1,t}^2 + u_{2,t}^2  \\\\\n",
    "&&\\text{s.t.} &&& x_{i,t+1} = x_{i,t} + \\Delta t v_{i,t+1}, && i \\in I, t \\in \\{0, 1, \\dots, n-1\\}\\\\\n",
    "&&&&& v_{i,t+1} = v_{i,t} + \\Delta t u_{i,t+1}, && i \\in I, t \\in \\{0, 1, \\dots, n-1\\}\\\\\n",
    "&&&&& x_{i,t} = xw_{i,t}, && i \\in I, t \\in \\mathcal{D}_{tw} \\\\\n",
    "&&&&& v_{i,0} = 0, && i \\in I \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This is a discrete time model that we can formulate with `JuMP.jl`, let's try it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Optimal Control in `JuMP.jl`\n",
    "**Problem**\n",
    "- Implement the above model in `JuMP.jl`\n",
    "- Complete the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, HiGHS\n",
    "\n",
    "# Set the parameters\n",
    "n = 60\n",
    "Δt = 60 / n \n",
    "I = 1:2\n",
    "\n",
    "# Set the waypoint data\n",
    "p = [1 4 6 1; 1 3 0 1]\n",
    "Dtw = [0, 25, 50, 60]\n",
    "xw = JuMP.Containers.DenseAxisArray(p, I, Dtw)\n",
    "\n",
    "# Define the model (finish using the HiGHS optimizer)\n",
    "model = \n",
    "\n",
    "# Add the variables (finish for each)\n",
    "@variable() # x[i, t], i ∈ I, t ∈ {0, 1, ..., n}\n",
    "@variable() # v[i, t], i ∈ I, t ∈ {0, 1, ..., n}\n",
    "@variable() # u[i, t], i ∈ I, t ∈ {1, ..., n}\n",
    "\n",
    "# Add the objective (finish)\n",
    "@objective() # minimize Σ_{t ∈ 1:n} u[1, t]^2 + u[2, t]^2\n",
    "\n",
    "# Add the constraints (finish)\n",
    "@constraint() # x[i, t+1] = x[i, t] + Δt v[i, t+1], i ∈ I, t ∈ {0, 1, ..., n-1}\n",
    "@constraint() # v[i, t+1] = v[i, t] + Δt u[i, t+1], i ∈ I, t ∈ {0, 1, ..., n-1}\n",
    "@constraint() # x[i, t] = xw[i, t], i ∈ I, t ∈ Dtw\n",
    "\n",
    "# Add the initial conditions (finish)\n",
    "fix.() # set v(0) = 0 hint: recall we can broadcast over a vector of variables\n",
    "\n",
    "# Optimize the model\n",
    "optimize!(model)\n",
    "\n",
    "# Get the results (finish)\n",
    "if has_values(model)\n",
    "    x_opt = # extract the values of x \n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "# Plot the path\n",
    "scatter(xw[1,:].data, xw[2,:].data, label = \"Waypoints\")\n",
    "plot!(x_opt[1, :].data, x_opt[2, :].data, label = \"Trajectory\")\n",
    "xlabel!(\"x_1\")\n",
    "ylabel!(\"x_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for this simple case, but we can start to think about some limitations:\n",
    "- What if we want to implement a non-uniform grid?\n",
    "- What about implementing (and switching between) derivative approximations (e.g., orthogonal collocation)?\n",
    "- What about higher fidelity integral approximations?\n",
    "- What about managing differing grid point between varied integral/derivative approximation schemes?\n",
    "- What if we want to solve our model without discretization?\n",
    "- What if we want to add uncertainty and/or PDE constraints?\n",
    "\n",
    "We could resolve the majority of the above points by manually deriving a finite formulation for `JuMP.jl` each time, but this is cumbersome and prone to error. Hence, it is common to define the model once in discrete time and call it good.\n",
    "\n",
    "However, characterizing models in discretized forms makes it likely for us to miss the insights we can gain from the infinite-dimensional form of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling in `InfiniteOpt.jl`\n",
    "`InfiniteOpt.jl` is built upon our unifying abstraction for infinite-dimensional optimization. Moreover, it leverages `JuMP`'s architecture to have an intuitive interface.\n",
    "\n",
    "Let's model the hovercraft optimal control problem in its native infinite-dimensional form using `InfiniteOpt.jl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using InfiniteOpt, HiGHS\n",
    "\n",
    "# Set the parameters\n",
    "v0 = zeros(2)\n",
    "I = 1:2\n",
    "p = [1 4 6 1; 1 3 0 1]\n",
    "Dtw = [0, 25, 50, 60]\n",
    "xw = JuMP.Containers.DenseAxisArray(p, I, Dtw)\n",
    "\n",
    "# Create the model\n",
    "model = InfiniteModel(HiGHS.Optimizer)\n",
    "\n",
    "# Decalare t as an infinite parameter\n",
    "@infinite_parameter(model, t ∈ [0, 60], num_supports = 61)\n",
    "\n",
    "# Add the infinite variables\n",
    "@variable(model, x[I], Infinite(t))\n",
    "@variable(model, v[I], Infinite(t))\n",
    "@variable(model, u[I], Infinite(t))\n",
    "\n",
    "# Set the objective\n",
    "@objective(model, Min, ∫(u[1]^2 + u[2]^2, t))\n",
    "\n",
    "# Add the constraints\n",
    "@constraint(model, ∂.(x, t) .== v)\n",
    "@constraint(model, ∂.(v, t) .== u)\n",
    "@constraint(model, [i ∈ I], v[i](0) == v0[i])\n",
    "@constraint(model, [i ∈ I, tw ∈ Dtw], x[i](tw) == xw[i, tw])\n",
    "\n",
    "# Optimize the model\n",
    "optimize!(model)\n",
    "\n",
    "# Get the results\n",
    "if has_values(model)\n",
    "    x_opt = value.(x)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "scatter(xw[1,:].data, xw[2,:].data, label = \"Waypoints\")\n",
    "plot!(x_opt[1], x_opt[2], label = \"Trajectory\")\n",
    "xlabel!(\"x_1\")\n",
    "ylabel!(\"x_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to express the model in its infinite form and `InfiniteOpt.jl` took care of the rest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What did we just do?\n",
    "We will walk through each step of what we just did and learn about how `InfiniteOpt.jl` works.\n",
    "\n",
    "First, we created a model object using `InfiniteModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InfiniteModel(HiGHS.Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide the `InfiniteModel` with an optimizer (one supported by `JuMP`) that will ultimately be used by the optimizer model backend to solve the model. More on that later...\n",
    "\n",
    "Next, following our abstraction, we declare time $t \\in [0, 60]$ as an infinite parameter using `@infinite_parameter` which follows a syntax similar to `@variable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@infinite_parameter(model, t ∈ [0, 60], num_supports = 61)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `num_supports` keyword tells the backend optimizer model we would like to use `61` support (discretization) points to solve the model. We discuss more about the backends and the arguments they take later on.\n",
    "\n",
    "Now that `t` is defined, let's add the infinite variables using `@variable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, x[I], Infinite(t))\n",
    "@variable(model, v[I], Infinite(t))\n",
    "@variable(model, u[I], Infinite(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the syntax for `@variable` is exactly the same as what we learned for `JuMP`. The only extra thing we do is add the `Infinite` tag containing the infinite parameters the variable depends on.\n",
    "\n",
    "We define objective using `@objective` in like manner to `JuMP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@objective(model, Min, ∫(u[1]^2 + u[2]^2, t)) # ∫ is unicode from \\int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we are able to directly express the integral using `∫` (we can also use `integral`) with respect to the infinite parameter `t`. Its domain is inferred, but we can specify a subdomain and the approximation method we would like to use; more on that later.\n",
    "\n",
    "Now we define ODEs using `@constraint`, expressing the derivatives with `∂` (can also use `deriv`) using `JuMP`'s broadcasting syntax for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, ∂.(x, t) .== v)\n",
    "@constraint(model, ∂.(v, t) .== u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the same constraint types and forms supported by `JuMP.jl`, are also supported in `InfiniteOpt.jl`!\n",
    "\n",
    "We also define the initial condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, [i ∈ I], v[i](0) == v0[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can enforce this point constraint by calling `v[i](0)`, this creates a point variable of `v[i](t)` at time 0.\n",
    "\n",
    "Next, we'll add the waypoint constraint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, [i ∈ I, tw ∈ Tw], x[i](tw) == xw[i, tw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we use the point variable syntax to enforce `x` at the waypoint time points `tw`.\n",
    "\n",
    "With our model defined, we can interrogate it via pretty printing it using `latex_formulation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_formulation(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to working with finite-time models, we can feasibly print interpretable models for real-world problems since the infinite-dimensional form is typically much more compact.\n",
    "\n",
    "With the model all setup, we can optimize it via `optimize!`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, our infinite-dimensional model was transformed into a `JuMP.jl` model (the optimizer model backend) via the default transformation method (direct transcription using the 61 supports specified above). We can take a quick sneak peak at the optimizer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is indeed a `JuMP.jl` model that uses the `HiGHS` optimizer (it also has some extra stuff to help it integrate seamlessly with the `InfiniteModel`). Note that pretty printing this discrete model would be impractical.\n",
    "\n",
    "Finally, to complete this example we query the results using `value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, we get a vector of values for each infinite variable `x[i](t)`. These correspond to the discrete time values used in the reformulation which we can also retrieve using `value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make other queries as we typically do with `JuMP` models. For instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show termination_status(model)\n",
    "@show primal_status(model)\n",
    "@show solve_time(model)\n",
    "@show objective_value(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Building Blocks of `InfiniteModel`s\n",
    "In this section, we go over the syntax for the modeling objects used in `InfiniteModel`s as per our unifying abstraction. \n",
    "\n",
    "Note that many of these constructs such as variables, expressions, objectives, constraints, etc. inherit all capabilities that `JuMP.jl`. `InfiniteOpt.jl` extends these to have additional capabilities needed for InfiniteOpt problems. Hence, our discussion will focus on these additional features.\n",
    "\n",
    "### Infinite Models\n",
    "The object behind it all, is the `InfiniteModel` itself. Typically, we will specify this with the optimizer we wish the default optimizer model backend (`TranscriptionOpt`) to use. We'll discuss optimizer models further below, but note that the following definitions are equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InfiniteModel(HiGHS.Optimizer, add_bridges = false)\n",
    "\n",
    "model = InfiniteModel()\n",
    "set_optimizer_model(model, TranscriptionModel(HiGHS.Optimizer, add_bridges = false))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TranscriptionModel` is an augmented `JuMP.Model`. Note that the arguments given to `InfiniteModel` are simply forwarded to the optimizer model. We can also provide the constructor of the optimizer backend directly: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InfiniteModel(HiGHS.Optimizer, OptimizerModel = TranscriptionModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not necessary in this case since `TranscriptionModel` is the default `OptimizerModel`.\n",
    "\n",
    "We can set the optimizer and attributes in like manner to `JuMP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InfiniteModel()\n",
    "set_optimizer(model, HiGHS.Optimizer)\n",
    "set_silent(model)\n",
    "set_optimizer_attribute(model, \"presolve\", \"on\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finite Parameters\n",
    "As we saw, `JuMP.jl` has limited support for using changeable parameters. `InfiniteOpt.jl` provides finite parameters whose values can be changed and which can be used in any expression. \n",
    "\n",
    "These are created via `@finite_parameter` which follows a similar syntax to `JuMP.jl`'s `@NLparameter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@finite_parameter(model, p == 42)\n",
    "@finite_parameter(model, ps[i ∈ 1:2] == i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, unlike `@NLexpression`, these parameters can be used anywhere in the model. We can query and modify the values with `value` and `set_value`, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show value(p)\n",
    "\n",
    "set_value(p, 10)\n",
    "\n",
    "@show value(p);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also delete parameters from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete(model, ps[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information (including anonymous definition) see https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/finite_parameter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infinite Parameters\n",
    "Infinite parameters serve as the core entity for defining infinite-dimensional modeling objects. They parameterize the domain of the problem (called the infinite domain). These are defined via `@infinite_parameter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@infinite_parameter(model, t ∈ [0, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will follow the syntax of `infinite_parameter(s)` in `infinite_domain`. In optimal control, we will typically be concerned time `t`, but we can also define other domain types like spatial position $x \\in [-1, 1]^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@infinite_parameter(model, x[1:2] in [-1, 1], independent = true, num_supports = 42, derivative_method = OrthogonalCollocation(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we can pass some keyword arguments as well:\n",
    "- `independent` indicates whether the parameters are independent such that their domain is computed via the Cartesian product\n",
    "- `num_supports` is an argument for the optimizer model indicating how many supports we'd like to use\n",
    "- `derivative_method` is another optimizer model argument indicating how we want to approximate the derivatives that depend on these parameters.\n",
    "\n",
    "We can also define random parameters with any distribution from `Distributions.jl`. For instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions, LinearAlgebra\n",
    "\n",
    "μ = zeros(4); Σ = I(4)\n",
    "@infinite_parameter(model, ξ[1:4] ~ MvNormal(μ, Σ), num_supports = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This enables us to tackle stochastic programs as well!\n",
    "\n",
    "We can also do some optimizer model related changes after definition. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_supports(t, [0, 0.3, 4, 10])\n",
    "set_derivative_method(t, FiniteDifference(Backward()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can delete infinite parameters if we want to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete(model, ξ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Create an Infinite Parameter\n",
    "**Problem**\n",
    "- Create an infinite parameter $\\ell \\in [-1, 1]$\n",
    "- Specify that it should use 10 supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information (including anonymous definition) see https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/parameter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Functions\n",
    "Sometimes we may wish to embed some arbitrary Julia function of infinite parameters into our model. This is often the case with setpoints in optimal control and experimental data in parameter estimation.\n",
    "\n",
    "While it is sometimes possible to represent these as explicit algebraic expressions, it is not always convenient or possible. To this end we provide, parameter functions via `@parameter_function` which follows a \n",
    "`JuMP`-like syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function setpoint(t)\n",
    "    if t <= 2\n",
    "        return 1.2\n",
    "    elseif t <= 5\n",
    "        return 3.0\n",
    "    elseif t <= 7\n",
    "        return 1.6\n",
    "    else\n",
    "        return 3.5\n",
    "    end\n",
    "end\n",
    "\n",
    "@parameter_function(model, mysetpoint == setpoint(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use `mysetpoint` in any expression in `InfiniteOpt.jl`, and it will be handled appropriately when the model is transformed. Note that functions must return a scalar number.\n",
    "\n",
    "Sometimes it is also convenient to use the functional definition API `parameter_function` with a Julia `do` block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysetpoint = parameter_function(t, name = \"setpoint\") do t\n",
    "    if t <= 5\n",
    "        return 2.0\n",
    "    else \n",
    "        return 10.2\n",
    "    end\n",
    " end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define a collection of parameter functions that depend on some parent function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent(t, a) = sin(t)^a\n",
    "\n",
    "@parameter_function(model, pfunc[i = 1:3] == t -> parent(t, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information (including anonymous definition) see https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/expression/#par_func_docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "All variables can be made with `@variable` just like any `JuMP.jl` variable, the only difference is that we'll add an appropriate \"tag\" to it.\n",
    "\n",
    "Let's begin with the most common: infinite variables.\n",
    "\n",
    "These use the `Infinite` tag as we have already seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, y >= 0, Infinite(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we can add bounds and conditions like normal.\n",
    "\n",
    "Uniquely, with infinite variables we can provide a start (guess) that a function with the same input dimensions as the variable. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, -1 <= w[i = 1:2] <= 1, Infinite(t), start = sin)\n",
    "model[:w] # macro objects are registered like they are in JuMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each $w_i(t)$ is set with an initial guess trajectory of $\\sin(t)$.\n",
    "\n",
    "Next, semi-infinite variables correspond to infinite variables whose domain is partially evaluated. We can define these using the `SemiInfinite` tag or via our functional syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, q, Infinite(t, x)) # an infinite variable \n",
    "\n",
    "@variable(model, q0, SemiInfinite(q, 0, x)) # macro definition\n",
    "\n",
    "q0 = q(0, x) # functional definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `q0` acts as an alias Julia variable. Note that simply invoking the functional syntax at different time point will have intuitive printing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q(1, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can define point variables using the convenient functional syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q(0, [-1, 1])\n",
    "y(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use `@variable` with the `Point` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, y0, Point(y, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can define finite variables by simply using the `@variable` as one normally would in `JuMP.jl`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, 0 ≤ z ≤ 4, Int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, variables can be modified/queried/deleted in like manner to those in `JuMP.jl` with the same functions. Some examples include:\n",
    "- `set_lower_bound`\n",
    "- `fix`\n",
    "- `set_binary`\n",
    "- `UpperBoundRef`\n",
    "- `set_start_value`\n",
    "- `delete`\n",
    "\n",
    "The only exception is that for infinite variables and derivatives the start values are queried/modified via `start_value_function` and `set_start_value_function`.\n",
    "\n",
    "We can also query the infinite parameters that a variable depends on via `parameter_refs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_refs(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Create Variables\n",
    "**Problem**\n",
    "- Add a variable $v(\\ell) \\in \\{0, 1\\}^2$\n",
    "- Create a point variable $v_1(-1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information (including anonymous definitions) see https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/variable/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differential Operators\n",
    "Differential operators capture how infinite variables vary with respect to infinite parameters. `InfiniteOpt.jl` currently supports derivative operators.\n",
    "\n",
    "These can be defined via `deriv` (alternatively, `∂` produced with `\\partial`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "∂(y, t) # make a first order derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can even operate directly on affine/quadratic expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "∂(2y * z - y^2 + 4y - z + 2, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the proper symbolic calculus rules are respected. We could even (unnecessarily) input an expression of infinite parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "∂(3t^2 + z * t - 3t + 4, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General nonlinear expressions however are not supported, but this can be added if there is enough interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "∂(sin(y)^3, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the error, notice that we just made a nonlinear expression without an `@NLexpression` macro, we'll talk more about that in the next section. \n",
    "\n",
    "To more efficiently parse large expression inputs and/or specify higher-order derivatives we can use `@deriv` (`@∂`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@∂(q, t^2, x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the derivative operators are applied recursively. Note, that a pending development will preserve higher-order derivatives. \n",
    "\n",
    "We can also define derivatives via `@variable` with the `Deriv` tag if we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, 0 <= dy <= 1, Deriv(y, t), start = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to convenient create an alias Julia variable, add bounds, and an initial guess value if wanted. We can also apply the same modification/query functions to derivatives as we can to infinite variables. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix(dy, 0, force = true)\n",
    "set_lower_bound(∂(q, t), 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create semi-infinite and/or point derivatives using the functional syntax or `@variable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy(0)\n",
    "∂(q, x[1])(0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Create a Derivative\n",
    "**Problem**\n",
    "- Add $\\frac{\\partial^2}{\\partial t^2}\\left[4q^2(t, x) + q(t, x)\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT CODE HERE\n",
    "@deriv(4q^2 + q, t^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information see https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/derivative/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressions\n",
    "`InfiniteOpt.jl` inherits the same expression syntax as `JuMP.jl`. Hence, for affine/quadratic expressions we can use `@expression` as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@expression(model, my_expr, q^2 + y - 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define expressions outside of macros (not recommended):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_expr = q^2 + y - 3 # defining outside macros is not as performant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One key difference with `InfiniteOpt.jl` vs. `JuMP.jl` is how we handle general nonlinear expressions. `InfiniteOpt.jl`'s nonlinear expressions permit the following:\n",
    "- define nonlinear expressions outside of macros\n",
    "- define expressions in the normal macros (not the `@NL` macros)\n",
    "- can use linear algebra operations\n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@expression(model, nl_expr, sin(y)^2 / q)\n",
    "nl_expr = sin(y)^2 / q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some linear algebra with nonlinear expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@variable(model, Q[1:2, 1:2]); @variable(model, W[1:2, 1:2]);\n",
    "\n",
    "@expression(model, W * Q * v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We support all the same native nonlinear functions as `JuMP.jl` with 3 caveats:\n",
    "- Functions from `SpecialFunctions.jl` can only be used if `using SpecialFunctions` is included first\n",
    "- The `ifelse` function must be specified `InfiniteOpt.ifelse`\n",
    "- The logic operators `&` and `|` must be used instead of `&&` and `||` when defining a nonlinear expression.\n",
    "\n",
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SpecialFunctions\n",
    "\n",
    "@show y^2.3 * gamma(y)\n",
    "@show InfiniteOpt.ifelse((y <= 0) | (y >= 3), y^2.3, exp(y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query all the registered nonlinear functions via `all_registered_functions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_registered_functions(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like `JuMP.jl` we can register unsupported functions. Here we use `@register`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfunc(a) = logerfcx(a) # functions from other packages must be wrapped\n",
    "@register(model, myfunc(a)) # `a` is an arbitrary symbol to indicate the argument structure\n",
    "myfunc(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here auto-differentiation is implied, but the gradient and the hessian functions can be given explicitly if wanted following `JuMP.jl`'s syntax.\n",
    "\n",
    "For more information, see https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/expression/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Operators\n",
    "Measure operators summarize an infinite variable/expression over a particular infinite parameter. `InfiniteOpt.jl` features a generic measure API, but more commonly users will use integrals and expectations.\n",
    "\n",
    "Integrals and expectations can be defined with `integral` (`∫` from `\\int`) and `expect` (`𝔼` from `\\bbE`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "𝔼(q * y + y, t) \n",
    "∫(q * t - sin(q), t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the integral uses the full domain of the infinite parameter by default. We can truncate the domain by specifying the bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "∫(q, t, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expectation uses the appropriate pdf with random infinite parameters. With other infinite parameters (e.g., $t$) the default pdf is $\\frac{1}{ub - lb}$, but we can specify a different one via the `pdf` keyword argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "𝔼(y, t, pdf = t -> exp(-t)) # here the pdf acts as a discount factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This introduces the notion of a time-valued pdf and expectation, we'll discuss this more later. \n",
    "\n",
    "Similarly, we can add a weighting function (mapping the infinite parameter to a scalar) to integrals via the `weight_func` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "∫(y, t, weight_func = t -> t^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For increased efficiency with handling expressions, we also provide `@integral`, `@∫`, `@expect`, and `@𝔼`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Differentiate an Integral\n",
    "**Problem**\n",
    "- Define $\\frac{d}{dx_1}\\left[\\int_{t \\in [0, 10]} q(t, x)^2 dt\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT CODE HERE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will discuss the approximation schemes for these in the transformation section.\n",
    "\n",
    "For more information see https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/measure/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "We define objectives using `@objective` like normal, typically these will contain measures that scalarize the cost function to be well-posed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@objective(model, Min, ∫(sin(y), t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can embed nonlinear expressions directly without using `@NLobjective`. \n",
    "\n",
    "One common mistake, is defining objectives without a fully reduced cost function (i.e., we don't measure all the infinite parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@objective(model, Min, ∫(q, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try that again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@objective(model, Min, ∫(∫(q, x), t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query/modify objectives just like one can in `JuMP.jl`.\n",
    "\n",
    "For more information, see https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/objective/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints\n",
    "Constraints are created in `InfiniteOpt.jl` using `@constraint`, `@NLconstraint` is not needed nor supported.\n",
    "\n",
    "Let's try some out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, sin(y) + z <= 0)\n",
    "@constraint(model, Q >= 0, PSDCone()) # all the special constraints from JuMP\n",
    "@constraint(model, [i ∈ 1:2], v[i]^2 + 5z >= 0) \n",
    "@constraint(model, sin.(v).^3 .== 0) # nonlinear broadcasting\n",
    "@constraint(model, 5z * y + q^2 <= 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while it is possible to create nonlinear vector constraints in `InfiniteOpt.jl`, these are not currently supported by any transformation backend.\n",
    "\n",
    "Commonly, we wish to enforce point constraints (e.g., boundary conditions), this can be accomplished using our functional point variable syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, initial, y(0) == 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define constraints whose domain is restricted to a portion of the infinite domain by adding `DomainRestrictions`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@constraint(model, y + 2z ≤ 0, DomainRestrictions(t => [2, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now this is limited to ranges, but development is underway to accept arbitrary logic. \n",
    "\n",
    "We can query/modify/delete constraints just like we can in `JuMP.jl` using the same methods. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete(model, initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Constraints\n",
    "**Problem**\n",
    "- Add $\\sum_{i \\in \\{1, 2\\}} \\tan(v_i(\\ell)) \\geq 42, \\; \\forall \\ell \\in [0, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUT CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, see https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/constraint/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations and Solution\n",
    "`InfiniteOpt` is based on a transformation paradigm. This is used to solve `InfiniteModel`s. In this section, we will highlight how this is done.\n",
    "\n",
    "### The Optimizer Model Framework\n",
    "As we highlighted above, `InfiniteModel`s contain an optimizer model backend (an augmented `JuMP.Model`) that is ultimately used to solve the infinite models.\n",
    "\n",
    "![transform](figures/transformation.png)\n",
    "\n",
    "Optimizer models store the transformed version of an `InfiniteModel` that can be handled by `JuMP.jl`. Moreover, they contain mapping information to support seamless interaction with `InfiniteModel`s.\n",
    "\n",
    "Optimizer models are queried via `optimizer_model` and are populated whenever `build_optimizer_model!` is called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InfiniteModel(HiGHS.Optimizer)\n",
    "@show optimizer_model(model)\n",
    "println()\n",
    "\n",
    "@infinite_parameter(model, t ∈ [0, 1], num_supports = 3)\n",
    "@variable(model, y ≥ 0, Infinite(t))\n",
    "@objective(model, Min, ∫(y, t))\n",
    "\n",
    "build_optimizer_model!(model)\n",
    "\n",
    "@show optimizer_model(model)\n",
    "\n",
    "latex_formulation(optimizer_model(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll discuss the particulars of what the `TranscriptionModel` backend transformation below, but here we can see how the model is transformed and stored in the optimizer model.\n",
    "\n",
    "Currently, we are working on generalizing this paradigm to accept arbitrary transformation backends (not just `JuMP.Model`s). See https://github.com/pulsipher/InfiniteOpt.jl/pull/248 to track the progress on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Transcription via `TranscriptionOpt`\n",
    "The default optimizer model backend in `InfiniteOpt.jl` is `TranscriptionOpt` which can apply a suite of discretization techniques to transform `InfiniteModel`s. These all fall under the umbrella of direct transcription. This principal is illustrated below:\n",
    "\n",
    "![transcription](figures/transcription.png)\n",
    "\n",
    "The general methodology for applying direct transcription is the following:\n",
    "1. Define supports (discretization points) for each infinite parameter\n",
    "2. Add any additional supports needed for derivative/integral approximation (e.g., collocation points)\n",
    "3. Generate the appropriate transcription variables\n",
    "4. Expand measures via an appropriate approximation scheme (e.g., trapezoid rule)\n",
    "5. Replace remaining infinite variables with transcription variables over each support combination\n",
    "6. Transcribe infinite constraints over all support combinations they depend on\n",
    "7. Add on auxiliary derivative approximation equations for derivative variables\n",
    "\n",
    "For instance, consider the simple space-time model:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\t&&\\min_{y(t), g(t, x)} &&& \\int_0^{10} y^2(t) dt \\\\\n",
    "\t&&\\text{s.t.} &&& y(0) = 1 \\\\\n",
    "\t&&&&& \\int_{x \\in [-1, 1]^2} \\frac{\\partial g(t, x)}{\\partial t} dx = 42, && \\forall t \\in [0, 10] \\\\\n",
    "  &&&&& 3g(t, x) + 2y^2(t) \\leq 2, && \\forall t \\in T, \\ x \\in [-1, 1]^2. \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Define supports for the infinite parameters $t$ and $x$:\n",
    "$$\n",
    "t \\in \\{0, 10\\}, \\;\\;\\;\\;\\; x \\in \\{[-1, -1]^T, [-1, 1]^T, [1, -1]^T, [1, 1]^T\\}\n",
    "$$\n",
    "Now we expand the integral measures via a trapezoid rule:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\t&&\\min_{y(t), g(t, x)} &&& 5y^2(0) + 5y^2(10) \\\\\n",
    "\t&&\\text{s.t.} &&& y(0) = 1 \\\\\n",
    "  &&&&& g(0, x) = 0 \\\\\n",
    "\t&&&&& \\frac{\\partial g(t, [-1, -1])}{\\partial t} + \\frac{\\partial g(t, [-1, 1])}{\\partial t} + \\frac{\\partial g(t, [1, -1])}{\\partial t} + \\frac{\\partial g(t, [1, 1])}{\\partial t} = 42, && \\forall t \\in [0, 10] \\\\\n",
    "  &&&&& 3g(t, x) + 2y^2(t) \\leq 2, && \\forall t \\in T, \\ x \\in [-1, 1]^2. \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Now we need to transcribe the remaining infinite variables and constraints:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\t&&\\min_{y(t), g(t, x)} &&& 5y^2(0) + 5y^2(10) \\\\\n",
    "\t&&\\text{s.t.} &&& y(0) = 1 \\\\\n",
    "  &&&&& g(0, [-1, -1]) = 0 \\\\\n",
    "  &&&&& g(0, [-1, 1]) = 0 \\\\\n",
    "  &&&&& g(0, [1, -1]) = 0 \\\\\n",
    "  &&&&& g(0, [1, 1]) = 0 \\\\\n",
    "\t&&&&& \\frac{\\partial g(0, [-1, -1])}{\\partial t} + \\frac{\\partial g(0, [-1, 1])}{\\partial t} + \\frac{\\partial g(0, [1, -1])}{\\partial t} + \\frac{\\partial g(0, [1, 1])}{\\partial t} = 42\\\\\n",
    "  &&&&& \\frac{\\partial g(10, [-1, -1])}{\\partial t} + \\frac{\\partial g(10, [-1, 1])}{\\partial t} + \\frac{\\partial g(10, [1, -1])}{\\partial t} + \\frac{\\partial g(10, [1, 1])}{\\partial t} = 42\\\\\n",
    "  &&&&& 3g(0, [-1, -1]) + 2y^2(0) \\leq 2 \\\\\n",
    "  &&&&& 3g(0, [-1, 1]) + 2y^2(0) \\leq 2 \\\\\n",
    "  &&&&& \\vdots \\\\\n",
    "  &&&&& 3g(10, [1, 1]) + 2y^2(10) \\leq 2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "Finally, we tag on the auxiliary derivative variable equations determined by backward finite difference:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&&& g(10, [-1, -1]) = g(0, [-1, -1]) + 10\\frac{\\partial g(10, [-1, -1])}{\\partial t} \\\\\n",
    "&&& g(10, [-1, 1]) = g(0, [-1, 1]) + 10\\frac{\\partial g(10, [-1, 1])}{\\partial t} \\\\\n",
    "&&& g(10, [1, -1]) = g(0, [1, -1]) + 10\\frac{\\partial g(10, [1, -1])}{\\partial t} \\\\\n",
    "&&& g(10, [1, 1]) = g(0, [1, 1]) + 10\\frac{\\partial g(10, [1, 1])}{\\partial t}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Let's see how `InfiniteOpt.jl` does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "inf_model = InfiniteModel()\n",
    "\n",
    "# Define parameters and supports\n",
    "@infinite_parameter(inf_model, t in [0, 10], supports = [0, 10])\n",
    "@infinite_parameter(inf_model, x[1:2] in [-1, 1], supports = [-1, 1], independent = true)\n",
    "\n",
    "# Define variables\n",
    "@variable(inf_model, y, Infinite(t))\n",
    "@variable(inf_model, g, Infinite(t, x))\n",
    "\n",
    "# Set the objective\n",
    "@objective(inf_model, Min, ∫(y^2, t))\n",
    "\n",
    "# Define the constraints\n",
    "@constraint(inf_model, y(0) == 1)\n",
    "@constraint(inf_model, con, g(0, x) == 0)\n",
    "@constraint(inf_model, ∫(∫(∂(g, t), x[1]), x[2]) == 42)\n",
    "@constraint(inf_model, 3g + y^2 <= 2)\n",
    "\n",
    "# Print the infinite model\n",
    "latex_formulation(inf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_optimizer_model!(inf_model)\n",
    "\n",
    "opt_model = optimizer_model(inf_model)\n",
    "latex_formulation(opt_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exactly matches what we did by hand! The support combinations are computed automatically. We can determine their values via `supports`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show supports(y)\n",
    "\n",
    "supports(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuple order corresponds to the infinite parameters of each, which we can check via `parameter_refs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show parameter_refs(y)\n",
    "\n",
    "@show parameter_refs(g);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `TranscriptionModel` is not just a regular `JuMP.Model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show is_transcription_model(opt_model)\n",
    "@show is_transcription_model(Model());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because a `TranscriptionModel` also contains transcription data, so we can map `inf_model` to `opt_model` behind the scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(transcription_data(opt_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access these mappings via `transcription_variable`, `transcription_expression`, and `transcription_constraint`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show transcription_variable(y)\n",
    "@show transcription_expression(y^2 + 2)\n",
    "transcription_constraint(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integral Approximations\n",
    "A wide variety of integral approximations (14 in total) are currently supported. These include:\n",
    "- Trapezoid rule (default)\n",
    "- Gaussian quadrature\n",
    "- Monte Carlo sampling\n",
    "\n",
    "The full list is provided at https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/measure/#Evaluation-Methods.\n",
    "\n",
    "Let's try specifying an integral that uses an appropriate Gauss quadrature scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InfiniteModel()\n",
    "@infinite_parameter(model, t ∈ [0, 1])\n",
    "@variable(model, y, Infinite(t))\n",
    "\n",
    "my_int = ∫(y, t, eval_method = Quadrature(), num_nodes = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it, `InfiniteOpt.jl` has a sophisticated support management system to properly keep track of where all supports come from and where they will be needed for transcription. \n",
    "\n",
    "We can interrogate what the approximation will look like using `expand`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expand(my_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `expand` should be avoided with models you intent to solve, since point/semi-infinite variables are added to the model prematurely to facilitate the preview. This is only intended as a method for curious users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivative Approximations\n",
    "For consistency, derivative approximation methods are associated with the infinite parameters the derivatives depend on. We can specify them when adding infinite parameters or later on via `set_derivative_method`. Currently, 4 such methods are supported:\n",
    "- Forward finite difference\n",
    "- Central finite difference\n",
    "- Backward finite difference (default)\n",
    "- Orthogonal collocation over finite elements with Lobatto quadrature\n",
    "\n",
    "To set orthogonal collocation with 3 nodes per finite element, we would write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InfiniteModel()\n",
    "@infinite_parameter(model, t ∈ [0, 1], num_supports = 3, derivative_method = OrthogonalCollocation(3))\n",
    "@variable(model, y, Infinite(t))\n",
    "\n",
    "@constraint(model, ∂(y, t) >= 0)\n",
    "@constraint(model, y(0) == 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will use 3 supports to construct the finite element boundaries (giving 2 finite elements). Later on collocation points will be added (1 extra per element). We can preview the derivative approximations via `evaluate_all_derivatives!` and `derivative_constraints`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_all_derivatives!(model)\n",
    "derivative_constraints(∂(y, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, these modify `model` in place and should not be used with models we actually want to solve.\n",
    "\n",
    "For more information, see https://pulsipher.github.io/InfiniteOpt.jl/stable/guide/derivative/#Derivative-Evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcription Solutions\n",
    "Querying the solution of an `InfiniteModel` is done in similar manner to `JuMP` models.\n",
    "\n",
    "Let's begin by creating and solving a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InfiniteModel(HiGHS.Optimizer)\n",
    "set_silent(model)\n",
    "@infinite_parameter(model, t in [0, 10], num_supports = 10)\n",
    "@variable(model, y >= 0, Infinite(t))\n",
    "@variable(model, z >= 0)\n",
    "@objective(model, Min, 2z)\n",
    "@constraint(model, c1, z >= y)\n",
    "@constraint(model, c2, y(0) == 42)\n",
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do all the model based queries in exactly the same way to `JuMP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show termination_status(model)\n",
    "@show primal_status(model)\n",
    "@show dual_status(model)\n",
    "@show has_values(model)\n",
    "@show objective_value(model)\n",
    "@show solve_time(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query the values of the variables and constraints using `value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show value(z)\n",
    "@show value(y)\n",
    "@show value(c1)\n",
    "@show value(c2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These correspond to the values of the transcription variables/constraints.\n",
    "\n",
    "We can also query the constraints as normal with methods like `dual` and `shadow_price`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show shadow_price(c1)\n",
    "@show shadow_price(c2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear models, we can even get the sensitivity report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = lp_sensitivity_report(model)\n",
    "@show report[c2]\n",
    "report[c1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also interrogate the transcription model directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_summary(transcription_model(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Solution Approaches\n",
    "As we will discuss in the last module today, `InfiniteOpt.jl` is modular and new transformation approaches can readily be added.\n",
    "\n",
    "Currently, `TranscriptionOpt` is the only backend available. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
